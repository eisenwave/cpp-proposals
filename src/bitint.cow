\cowel_include{libwg21.cow}

\wg21_head(
    title = Bit-precise integers
){
\dl{
  \dt{Document number:} \dd{\docnum{D3666R0}}
  \dt{Date:}            \dd{\tt{2025-09-05}}
  \dt{Audience:}        \dd{SG6, SG22, EWG}
  \dt{Project:}         \dd{ISO/IEC 14882 Programming Languages — C++, ISO/IEC JTC1/SC22/WG21}
  \dt{Reply-to:}        \dd{Jan Schultke <\mail{janschultke@gmail.com}>}
  \dt{GitHub Issue:}    \dd{\ref(https://wg21.link/P3666/github)}
  \dt{Source:}          \dd{\ref(https://github.com/Eisenwave/cpp-proposals/blob/master/src/bitint.cow)}
}
\hr
}

\Babstract{
C23 has introduced so-called "bit-precise integers" into the language,
which should be brought to C++ for compatibility, among other reasons.
Following an exploration of possible designs in \ref(P3639R0) "The \tt{_BitInt} Debate",
this proposal introduces a new set of fundamental types to C++.
}

\Bimp{
This draft is super early work-in-progress.
The wording is not anywhere near complete,
and the discussion needs to be fleshed out substantially.
}

\h2(listed=false){Contents}

\make_contents

\h2{Revision history}

This is the first revision.

\h2{Introduction}

\ref(N2763) introduced the \tcode{_BitInt} set of types to the C23 standard,
and \ref(N2775) further enhanced this feature with literal suffixes.
For example, this feature may be used as follows:

\cppblock{
// 8-bit unsigned integer initialized with value 255.
// The literal suffix wb is unnecessary in this case.
unsigned _BitInt(8) x = 0xFFwb;
}

In short, the behavior of these \dfn{bit-precise integers} is as follows:

\ul{
  \li{
    No integer promotion to \tcode{int} takes place.
  }
  \li{
    Mixed-signedness comparisons, implicit conversions,
    and other permissive feature are supported.
  }
  \li{
    They have lower conversion rank than standard integers,
    so an operation between \tcode{_BitInt(8)} and \tcode{int} yields \tcode{int},
    as does an operation with \tcode{_BitInt(N)} where \tcode{N} is the width of \tcode{int}.
    They only have greater conversion rank when their width is greater.
  }
}

\h2{Motivation}

\h3{Computation beyond 64 bits}

Computation beyond 64-bit bits, such as with 128-bits is immensely useful.
A large amount of motivation for 128-bit computation can be found in \ref(P3140R0).
Computations in cryptography, such as for RSA require even 4096-bit integers.

\h3{C ABI compatibility}

C++ currently has no portable way to call C functions such as:

\cppblock{
_BitInt(32)  plus( _BitInt(32) x,  _BitInt(32) y);
_BitInt(128) plus(_BitInt(128) x, _BitInt(128) y);
}

While one could rely on the ABI of \tcode{uint32_t} and \tcode{_BitInt(32)}
to be identical in the first overload,
there certainly is no way to portably invoke the second overload.

This compatibility problem is not a hypothetical concern either; it is an urgent problem.
There are already targets with \tcode{_BitInt} supported by major compilers,
and used by C developers:

\style{
  .center {
    margin-left: auto;
    margin-right: auto;
  }
}

\table(class=center){
  \tr{
    \th{Compiler}
    \th{\tt{BITINT_MAXWIDTH}}
    \th{Targets}
    \th{Languages}
  }
  \tr{
    \td{clang 16+}
    \td{\tcode{8'388'608}}
    \td{all}
    \td{C & C++}
  }
  \tr{
    \td{GCC 14+}
    \td{\tcode{65'535}}
    \td{64-bit only}
    \td{C}
  }
  \tr{
    \td{MSVC}
    \td{\N{CROSS MARK}}
    \td{\N{CROSS MARK}}
    \td{\N{CROSS MARK}}
  }
}

\h3{Resolving issues with the current integer type system}

\tcode{_BitInt} as standardized in C solves multiple issues that
the standard integers (\tcode{int} etc.) have.
Among other problems,
integer promotion can result in unexpected signedness changes.

\Bex{
The following code has undefined behavior
if \tcode{int} is a 32-bit signed integer (which it is on many platforms).

\cppblock{
uint16_t x = 65'535;
uint16_t y = x * x;
}

During the multiplication \tcode{x * x},
\tcode{x} is promoted to \tcode{int},
and the result of the multiplication \tcode{4'294'836'225}
is not representable as a 32-bit signed integer.
Therefore, signed integer overflow takes places \N{HORIZONTAL ELLIPSIS} given unsigned operands.
}

\Bex{
The following code may have surprising effects
if \tcode{std::uint8_t} is an alias for \tcode{unsigned char}
and gets promoted to \tcode{int}.

\cppblock{
std::uint8_t x = 0b1111'0000;
std::uint8_t y = ~x >> 1; // y = 0b1000'01111
}

Surprisingly, \tcode{y} is not \tcode{0b111}
because \tcode{x} is promoted to \tcode{int} in \tcode{~x},
so the subsequent right-shift by \tcode{1} shifts one set bit into \tcode{y} from the left.
Even more surprisingly, if we had used \tcode{auto} instead of \tcode{std::uint8_t} for \tcode{y},
\tcode{y} would be \tcode{-121},
despite our code seemingly using only unsigned integers.
}

Overall, the current integer promotion semantics are extremely surprising
and make it hard to write correct code involving promotable unsigned integers.

Furthermore, there is no portable way to use an integer with exactly 32 bits.
\tcode{std::int_least32_t} and \tcode{long} may be wider,
and \tcode{std::int32_t} is an optional type alias which only exists if such an integer type
has no padding bits.
While most users can use \tcode{std::int32_t} without much issue,
its optionality is a problem for use in the standard library and other ultra-portable libraries.

\h2{Design discussion}

The overall design strategy is as follows:

\ul{
  \li{
    The proposal is a C compatibility proposal first and foremost.
    Whenever possible, we match the behavior of the C type.
  }
  \li{
    The goal is to deliver a minimal viable product (MVP)
    which can be integrated into the standard as quickly as possible.
    This gives us plenty of time to add standard library support wherever desirable over time,
    as well as other convenience features surrounding \tcode{_BitInt}.
  }
}

\h3{Why not make it a library type?}

\ref(P3639R0) explored in detail whether to make it a fundamental type or a library type.
Furthermore, feedback given by SG22 and EWG was to make it a fundamental type, not a library type.
This boils down to two plausible designs
(assuming \tcode{_BitInt} is already supported by the compiler), shown below.

\style{
#tony-table {
    margin-left: auto;
    margin-right: auto;
    width: 90%;
    table-layout: fixed;
}
#tony-table td {
    background-color: var(--deep-background-color);
    width: 50%;
}
}

\table(id=tony-table){
\tr{
    \th{\N{MATHEMATICAL DOUBLE-STRUCK CAPITAL F} \N{EN DASH} Fundamental type}
    \th{\N{MATHEMATICAL DOUBLE-STRUCK CAPITAL L} \N{EN DASH} Library type}
}
\tr{
\td{\codeblock(cpp, borders=false){
template <size_t N>
using bit_int =
    _BitInt(N);




template <size_t N>
using bit_uint =
    unsigned _BitInt(N);
}}
\td{\codeblock(cpp, borders=false){
template <size_t N>
class bit_int {
  private:
    _BitInt(N) _M_value;
  public:
    // ...
};
template <size_t N>
class bit_uint
  { /* ... */; };
}}
}
}

The reasons why we should prefer the left side are described in the following subsections.

\h4{Full C compatibility requires fundamental types}

\tcode{_BitInt} in C can be used as the type of a bit-field, among other places:

\cppblock{
struct S {
    // 1. _BitInt as the underlying type of a bit-field
    _BitInt(32) x : 10;
};

// 2. _BitInt in a switch statement
_BitInt(32) x = 10;
switch (x) {}

// 3. _BitInt used as a null pointer constant
void* p = 0wb;
}

Since C++ does not support the use of class types in bit-fields,
such a \tcode{struct S} could not be passed from C++ to a C API.
A developer would face \em{severe} difficulties
when porting C code which makes use of these capabilities to C++
and if bit-precise integers were a class type in C++.

\h4{C compatibility would require an enormous amount of operator overloads etc.}

Integer types can be used in a large number of places within the language.
If we wanted a \tcode{std::bit_int} class type to be used in the same places
(which would be beneficial for C-interoperable code),
we would have to add a significant amount of operator overloads
and user-defined conversion functions:

\ul{
  \li{There are conversion to/from floating-point types and other integral types.}
  \li{There are conversion to/from enumeration types.}
  \li{
    There are conversion to/from pointers,
    at least for \tcode{_BitInt}s of the same width as \tcode{uintptr_t}.
  }
  \li{
    Integers can be used to add offsets onto pointers, and by proxy,
    in the subscript operator of builtin arrays.
  }
  \li{
    Arithmetic operators can be used to operate between any mixture of arithmetic types,
    such as \tcode{_BitInt(32) + float}.
  }
}

Any discrepancies would lead to some code using bit-precise integers behaving
differently in C and C++, which is undesirable.

Furthermore, the \tcode{wb} \grammarterm{integer-suffix} for \tcode{_BitInt}
is fairly complicated to implement as a library feature
because the resulting type depends on the numeric value of the literal.
This means it would presumably be implemented like:

\: manual highlights are workaround for https://github.com/eisenwave/ulight/issues/109
\cppblock{
template<char... Chars>
  constexpr auto \hl(keyword){operator}""wb() { /* ... */ }
template<char... Chars>
  constexpr auto \hl(keyword){operator}""WB() { /* ... */ }
template<char... Chars>
  constexpr auto \hl(keyword){operator}""uwb() { /* ... */ }
template<char... Chars>
  constexpr auto \hl(keyword){operator}""UWB() { /* ... */ }
template<char... Chars>
  constexpr auto \hl(keyword){operator}""uWB() { /* ... */ }
template<char... Chars>
  constexpr auto \hl(keyword){operator}""Uwb() { /* ... */ }
}

Seeing that properly emulating C's behavior for \tcode{_BitInt} (and its suffixes)
requires a mountain of complicated operator overload sets,
user-defined conversion functions,
converting constructors, and
user-defined literals,
it seems unreasonable to go this direction.

A major selling point of a library type is that library types have more teachable interfaces,
since the user simply needs to look at the declared members of the class
to understand how it works.
If the interface is a record-breaking convoluted mess,
this benefit is lost.
If we choose not to add all this functionality,
then we lose a large portion of C compatibility.
Either option is bad, and making \tcode{std::bit_int} a fundamental type
seems like the only way out.

\h4{Constructors cannot signal narrowing}

Some C++ users prefer list initialization because it prevents narrowing conversion.
This can prevent some mistakes/questionable code:

\cppblock{
unsigned x = -1; // OK, x = UINT_MAX, but this looks weird
unsigned y{ -1 };  // error: narrowing conversion
}

This would not be feasible if \tcode{std::bit_int} was a library type
because narrowing cannot be signaled by constructors.
Consider that \tcode{std::bit_int} and \tcode{std::bit_uint}
should have a non-explicit constructor (template)
accepting \tcode{int} (and other integral types) to enable compatibility in situations like:

\cppblock{
#ifdef __cplusplus
typedef std::bit_uint<32> u32; // C++
#else
typedef unsigned _BitInt(32) u32; // C
#endif
// Common C and C++ code, possibly in a header:

// OK, converting int → u32.
// Using "incorrectly typed" zeros is fairly common, both in C and in C++.
u32 x = 0;
// OK, same conversion, but would be considered narrowing in C++.
// Not very likely to be written.
u32 y = -1;
}

If such a \tcode{std::bit_uint<32>(int)} constructor existed,
the following C++ code would not raise any errors:

\cppblock{
std::bit_uint<32> x{ 0 };  // OK, as expected
std::bit_uint<32> y{ -1 }; // OK?! But this looks narrowing!
}

This code simply calls a \tcode{std::bit_uint<32>(int)} constructor,
and while the initialization of \tcode{y} is \em{spiritually} narrowing,
no narrowing conversion actually takes place.
In conclusion,
if \tcode{std::bit_int} was a library type,
C++ users who use this style would lose what they consider a valuable safety guarantee.

\Bnote{
It can be argued that using list-initialization for this purpose is an anti-pattern
and only solves a subset of the issues that compiler warnings and linter warnings should address.
Personally, I have no strong position on this issue.
}

\h4{Tiny integers are useful in C++}

In some cases, tiny \tcode{bit_int}'s may be useful as the underlying type of an enumeration:

\cppblock{
enum struct Direction : bit_int<2> {
    north, east, south, west,
};
}

By using \tcode{bit_int<2>} rather than \tcode{unsigned char},
every possible value has an enumerator.
If we used e.g. \tcode{unsigned char} instead,
there would be 252 other possible values that simply have no name,
and this may be detrimental to compiler optimization of \tcode{switch} statements etc.

\h4{Special deduction rules}

While this proposal focuses on the minimal viable product (MVP),
a possible future extension would be new deduction rules allowing the following code:

\cppblock{
template <size_t N>
void f(bit_int<N> x);

f(int32_t(0)); // calls f<32>
}

Being able to make such a call to \tcode{f} is immensely useful because it would allow
for defining a single function template which may be called with every possible
signed integer type,
while only producing a single template instantiation
for \tcode{int}, \tcode{long}, and \tcode{_BitInt(32)},
as long as those three have the same width.
The prospect of being able to write bit manipulation utilities that simply accept
\tcode{bit_uint<N>} is quite appealing.

If \tcode{bit_int<N>} was a class type,
this would not work because template argument deduction would fail,
even if there existed an implicit conversion sequence from \tcode{int32_t}
to \tcode{bit_int<32>}.
These kinds of deduction rules may be shutting the door on this mechanism forever.

\h4{Quality of implementation requires a fundamental type}

While a library type \tcode{class bit_int} gives the implementation
the option to provide no builtin support for bit-precise integers,
to achieve high-quality codegen,
a fundamental type is \em{inevitably} needed anyway.
If so, \tcode{class bit_int} is arguably adding pointless bloat.

For example, when an integer division has a constant divisor, like \tcode{x / 10},
it can be optimized to a fixed-point multiplication,
which is much cheaper.
Performing such an optimization requires the compiler to be aware that a division is taking place,
and this fact is lost when division is implemented in software,
as a loop which expands to hundreds of IR instructions.

"Frontend awareness" of these operations is also necessary to provide compiler warnings
when a division by zero or a bit-shift with undefined behavior is spotted.
Use of \tcode{pre} on e.g. \tcode{bit_int::operator/} cannot be used to achieve this
because numerics code needs to have no hardened preconditions and no contracts,
for performance reasons.
Another workaround would be an ever-growing set of implementation-specific attributes,
but at that point, we may as well make it fundamental.

\h3{Naming}

The approach is to expose bit-precise integers via two alias templates:

\cppblock{
template <size_t N>
using bit_int = _BitInt(N);

template <size_t N>
using bit_uint = unsigned _BitInt(N);
}

The goal is to have a spelling reminiscent of the C \tcode{_BitInt} spelling.
There are no clear problems with it,
so it is the obvious candidate.

\h4{Why no \tcode{_t} suffix?}

While the \tcode{_t} suffix would be conventional for simple type aliases
such as \tcode{uint32_t},
there is no clear precedent for alias templates.
There are alias templates such as \tcode{expected::rebind}
without any \tcode{_t} or \tcode{_type} suffix,
but "type trait wrappers" such as \tcode{conditional_t} which have a \tcode{_t} suffix.

The \tcode{_t} suffix does not add any clear benefit,
adds verbosity,
and distances the name from the C spelling \tcode{_BitInt}.
Brevity is important here because \tcode{bit_int}
is expected to be a commonly spelled type.
A function doing some bit manipulation could use this name numerous times.

\h4{Why the keyword spelling?}

I also propose to standardize the keyword spelling
\tcode{_BitInt} and \tcode{unsigned _BitInt}.
While a similar approach could be taken as with the \tcode{\hl(macro){_Atomic}}
compatibility macro,
macros cannot be exported from modules,
and macros needlessly complicate the problem compared to a keyword.

The objections to a keyword spelling are that it's not \em{really} necessary,
or that it "bifurcates" the language by having two spellings for the same thing,
or that those ugly C keywords should not exist in C++.
Ultimately, it's not the job of WG21 to police code style;
both spellings have a right to exist:

\ul{
  \li{
    The \tcode{std::bit_int} alias template fits in aesthetically with the rest of the language,
    and conveys clearly (via "pointy brackets") that the given width is a constant expression.
  }
  \li{
    The \tcode{_BitInt} spelling is useful for writing C/C++-interoperable code,
    and C compatibility is an important design goal.
    Furthermore, the spelling is going to exist whether that would be a compatibility macro
    or a keyword,
    and since there is no clear technical benefit to a macro,
    it should be a keyword.
  }
}

Furthermore, to enable C compatibility, all of the spellings
\tcode{_BitInt}, \tcode{signed _BitInt} and \tcode{unsigned _BitInt} need to be valid.
This goes far beyond the capabilities that a compatibility macro like \tcode{\hl(macro){_Atomic}}
can provide without language support.
The most likely wording path would be to create an exposition-only \tcode{\exposid{bit-int}}
spelling to define \tcode{signed \exposid{bit-int}} etc., which makes our users beg the question:

\Bquote{
Why is there an compatibility macro for an exposition-only keyword spelling?!
Why are we making everything more complicated by not just copying the keyword from C?!
Why is this exposition-only when it's clearly useful for users to spell?!
}

\Bnote{
Clang already supports the \tcode{_BitInt} keyword spelling as a compiler extensions,
so this is standardizing existing practice.
}

\h3(id=underlying-bitint){Underlying type of enumerations}

The following C code is ill-formed:

\cppblock{
// error: '_BitInt(32)' is an invalid underlying type
enum S : _BitInt(32) { x = 0 };
}

There is no obvious reason why \tcode{_BitInt} must not be a valid underlying type.
However, since this feature is not needed for C compatibility,
I do not consider bit-precise integers as underlying types to be part of the MVP.
A follow-up proposal could add this feature later,
possibly in coordination with WG14.

\Bnote{
See \ref(N3550) §6.7.3.3 "Enumeration specifiers" for restrictions.
}

This behavior should be mirrored.

\h3{Should it be optional? Is this too hard to implement?}

As in C, \tcode{_BitInt(N)} is only required to support \tcode{N}
of at least \tcode{LLONG_WIDTH}, which has a minimum of \tcode{64}.
This makes \tcode{_BitInt} a semi-optional feature,
and it is reasonable to mandate its existence, even in freestanding platforms.

Of course, this has the catch that \tcode{_BitInt} may be completely useless
for tasks like 128-bit computation.
As unfortunate as that is, the MVP should include no more than C actually mandates.
Mandating a greater minimum width could be done in a future proposal.

\h3(id=bit-int-1){\tt{_BitInt(1)}}

C23 does not permit \tcode{_BitInt(1)} but does permit \tcode{unsigned _BitInt(1)},
mostly for historical reasons
(C did not always requires two's complement representation for signed integers).
This is an irregularity that could make generic programming harder in C++.

However, there are already plans to lift the restriction for C2y;
see \ref(N3644).
Following v3 of the proposal,
\tcode{_BitInt(1)} is expected to be valid type,
and \tcode{0wb} should be of type \tcode{_BitInt(1)} rather than \tcode{_BitInt(2)}.
That proposal also contains some practical motivation for why
a single-bit should be permitted.

\Bnote{
If \tcode{_BitInt(1)} was allowed,
it would be able to represent the values \tcode{0} and \tcode{-1},
just like an \tcode{int x : 1;} bit-field.
}

\h3{Template argument deduction}

The following code should be valid:

\cppblock{
template <std::size_t N>
void f(std::bit_int<N>);

int main() {
    f(std::bit_int<3>{}); // OK, N = 3
}
}

This would be a consequence of deduction from \tcode{_BitInt} being valid:

\cppblock{
template <unsigned N>
void f(_BitInt(N));
template <int N>
void g(_BitInt(N));

int main() {
    f(_BitInt(3)(0)); // OK, N = 3
    g(_BitInt(3)(0)); // OK, N = 3
}
}

This behavior is already implemented by Clang as a C++ compiler extension,
and makes deduction behave identically to deducing sizes of arrays.
In general, the aim is to make the deduction of \tcode{_BitInt} widths
as similar as possible to arrays because users are already familiar with the latter.
It is also clearly useful because it allows writing templates
that can accept \tcode{_BitInt} of any width.

While this behavior could arguably be excluded from the MVP,
it would be extremely surprising to users if such deduction was not possible,
given that appearance of \tcode{std::bit_int}.
If deducing \tcode{N} from \tcode{std::array<T, N>} is possible,
why would it not be possible to deduce \tcode{N} from \tcode{std::bit_int<N>}?

One thing deliberately not allowed is:
\cppblock{
_BitInt x = 123wb;
std::bit_int y = 123wb;
}

This class-template-argument-deduction-like construct is not part of the MVP and if desired,
should be proposed separately.
Even if it was allowed, \tcode{std::bit_int} is proposed to be an alias template,
and alias templates do not support "forwarding deduction" to CTAD.

\h3{Undefined behavior on signed integer overflow}

I propose to perpetuate bit-precise integers having undefined behavior
on signed integer overflow, just like \tcode{int}, \tcode{long} etc.
This has a few reasons:

\ul{
  \li{
    bit-precise integers have undefined overflow in C,
    so this is what users are used to.
  }
  \li{
    "Solving" signed integer overflow for bit-precise integers is not part of the MVP.
    Undefined behavior can always be defined to do something else,
    so there is no urgent need for this paper to address this issue,
    rather than solving it in a follow-up paper.
  }
  \li{
    Signed integer overflow having undefined behavior is a much broader issue
    that should be looked at in general, for all integer types,
    not just bit-precise integer types.
    Perhaps hardened implementations could have wrapping overflow with erroneous behavior.
    In any case, the problem exceeds the scope of the paper.
  }
  \li{
    It is highly unusual that users would expect signed integer overflow to be well-behaved,
    such as having wrapping behavior.
    Adding two positive numbers and obtaining a negative number is not typically useful.
  }
  \li{
    The undefined behavior here is useful.
    It allows for optimizations such as converting \tcode{x + 3 < 0} into \tcode{x < -3}.
  }
}

\h3(id=preprocessor){No preprocessor changes, for better or worse}

To my understanding, no changes to the preprocessor are required.
\ref(N2763) did not make any changes to the C preprocessor either.
In most contexts, integer literals in the preprocessor are simply a \grammarterm{pp-number},
and their numeric value or type is irrelevant.

Within the controlling constant expression of an \tcode{#if} directive,
all signed and unsigned integer types
behave like \tcode{intmax_t} and \tcode{uintmax_t}\iref{cpp.cond},
which may be surprising.

\Bex{
The following code is ill-formed
if \tcode{intmax_t} is a 64-bit signed integer (which it is on many platforms):
\cppblock{
#if \cowel_highlight(cpp){1'000'000'000'000'000'000'000'000wb} // error
#endif
_BitInt(81) x = 1'000'000'000'000'000'000'000'000wb; // OK
}
\tcode{#if \cowel_highlight(cpp){1'000'000'000'000'000'000'000'000wb}} is ill-formed
because the integer literal is of type \tcode{_BitInt(81)},
which behaves like \tcode{intmax_t} within \tcode{#if}.
Since \math{\msup{\mn{10}\mn{32}}} does not fit within \tcode{intmax_t},
the literal is ill-formed\iref{lex.icon#4}.
}

The current behavior could be seen as suboptimal
because it makes bit-precise integers dysfunctional within the preprocessor.
However, the preprocessor is largely "owned" by C,
and any fix should go through WG14.
In any case, fixing the C preprocessor is not part of the MVP.

\h3{Degree of library support}

As previously stated,
the overall strategy of this proposal is to ship an MVP.
There are three categories of library features that deal with integer types:

\ul{
  \li{
    Features which are stated to support any integer type,
    such as \header{bit} or \header{simd}.
    These should generally support bit-precise integers too,
    since there's typically no reason to single out bit-precise integers,
    and support would be useful.
    In the long run, it seems implausible that e.g. \header{bit} would not support
    bit-precise integers as this support is clearly useful and would improve consistency.
    Forbidding bit-precise integers only to introduce support for them later would
    only add a bunch of busy-work for LWG.
  }
  \li{
    Functions originating from C with support for bit-precise integer types,
    such as \tcode{std::sqrt}.
    The C functions typically support only bit-precise integers with the same width as
    some standard integer type.
    This restriction is unmotivated in C++ since a function template can easily cover
    any bit-precise integer rather than having a finite set of options
    covered by C's \tcode{_Generic} selection,
    so we introduce a function template overload instead.
  }
  \li{
    Features which explicitly support only standard integers,
    such as \tcode{std::to_string} or the \tcode{std::bitset} constructors.
    These should be addressed by follow-up proposals
    because they are not part of the MVP.
  }
}

\h3{\tcode{std::format}, \tcode{std::to_chars}, etc.}

I consider printing support to be part of the MVP for bit-precise integers.
This is in part because it would take considerable wording effort to exclude
support for bit-precise integers from these facilities,
only for it to be reverted once support is inevitably added.

\Bex{
The expression \tcode{std::println("{:b}", 100)} prints \tt{1100100}.
This is specified in terms of \tcode{std::to_chars} where \tcode{base = 2}.
If \tcode{std::to_chars} does not actually support bit-precise integers,
this wording becomes nonsensical.
}

\h3(id=preventing-iota-view-abi-break){Preventing \tcode{ranges::iota_view} ABI break}

Due to the current wording in \eelis{range.iota.view#1},
adding bit-precise integers or extended integers of greater width than \tcode{long long}
potentially forces the implementation to redefine
\tcode{ranges::iota_view::iterator::difference_type}.
Changing the type would be an ABI break.
This problem is similar to historical issues with \tcode{intmax_t},
where adding 128-bit integers would force the implementation to redefine the former type.

To prevent this, we tweak the wording in \ref(#wording-iota-view)
so that new extended or bit-precise integers may be added.
This extends slightly beyond the scope of the MVP,
but it would be silly to leave the wording in an undesirable state,
where adding a 128-bit extended integer still constitutes an ABI break.

\h3{Bit-precise \tcode{size_t}, \tcode{ptrdiff_t}}

As in C,
the proposal allows for \tcode{size_t} and \tcode{ptrdiff_t} to be bit-precise integers.

Whether such an implementation is desirable is for implementers and users to decide,
but from the perspective of the C standard and the C++ standard,
there is no compelling reason to disallow it.
It would be a massive breaking change if existing C++ implementations redefined
the type of these,
so it is unlikely we will see an implementation that makes use of this freedom anytime soon.

\h3{Passing \tcode{std::bit_int} into standard library function templates}

Unlike standard integers,
it is plausible that some bit-precise integers are too large to be passed on the stack,
or at least too large to make this the "default option".
Nonetheless,
all proposed library functions which operate on \tcode{std::bit_int}
should accept \tcode{std::bit_int} by value.

\Bex{
The proposal adds this \tcode{std::abs} overload:
\cppblock{
template<size_t N>
  constexpr abs(bit_int<N> j);
}

If implemented verbatim like this,
in the \ref(https://gitlab.com/x86-psABIs/x86-64-ABI){x86-64 psABI},
\tcode{bit_int<64>} would be passed via single register,
\tcode{bit_int<128>} would be passed via a pair of registers,
and any wider integer integer would be pushed onto the stack.
Passing via stack is questionable and may result in an immediate program crash
when millions of bits are involved.
}

The reason for having such signatures
is that the details of how values are passed into functions
are outside the scope of the standard.
Since most functions in the standard are not addressable,
and since we don't care about keeping the results of reflecting on the standard library stable,
the actual overload sets in the library implementation can differ from the declarations
in the standard.

\Bex{
An implementation of the \tcode{abs} function template could look as follows:

\cppblock{
template<size_t __n>
constexpr abs(_BitInt(__n) __j) { // pass small integers by value
    return __j >= 0 ? __j : -__j;
}

template<size_t __n>
  requires (sizeof(_BitInt(__n)) > __pass_by_value_max_size)
constexpr abs(const _BitInt(__n)& __j) { // pass large integers by reference
    return __j >= 0 ? __j : -__j;
}
}

Another plausible implementation strategy is to
use an ABI-altering, implementation-specific attribute.
\cppblock{
template<size_t __n>
constexpr abs([[impl::pass_large_by_ref]] _BitInt(__n) __j) {
    return __j >= 0 ? __j : -__j;
}
}
Such an attribute could alter the ABI for \tcode{__j}
so that it is passed indirectly (via address) beyond a certain size,
not on the stack.
}

Admittedly, having the standard pass all integers by value may give the user
the false impression that there is no problem,
which is problematic.
However, it is seemingly the lesser evil,
since the alternative is wasting LEWG and LWG time on quality of implementation.

\h2{Education}

Following SG20 Education recommendations at Sofia 2025,
this proposal contains guidance on how bit-precise integers
are meant to be taught by learning resources.

\h3{Teaching principles}

\ol{
  \li{
    Emphasize familiar features.
    The closest equivalents to \tcode{std::bit_int} and \tcode{std::bit_uint}
    are \tcode{std::intN_t} and \tcode{std::uintN_t}, respectively.
  }
  \li{
    Clearly distinguish \tcode{std::bit_int} from other existing integer types.
    It should be clarified that \tcode{std::bit_int} is always a distinct type
    from the \tcode{std::intN_t} aliases, even if it behaves similarly.
    Furthermore, the major differences are:
    \ul{
      \li{
        \tcode{std::bit_int} is not optional (though there exists a maximum width),
        whereas any \tcode{std::intN_t} may not actually exist.
      }
      \li{
        \tcode{std::bit_int} is not subject to integer promotion,
        unlike any of the existing standard integer types.
      }
      \li{
        \tcode{std::bit_int} cannot be used as the underlying type of enumerations.
      }
    }
  }
  \li{
    Only reference the \tcode{_BitInt} spelling in a note on C compatibility.
    \tcode{_BitInt(N)} looks nothing like the class templates that C++ users are used to,
    and nothing suggests that \tcode{N} is required to be a constant expression.
    The \tcode{std::bit_int} and \tcode{std::bit_uint} alias templates
    should be taught first and foremost.
  }
  \li{
    Point out potential pitfalls:
    \ul{
      \li{
        \tcode{std::bit_int} has a \tcode{BITINT_MAXWIDTH} which is not guaranteed
        to be any more than \tcode{64}.
        The user should be made aware of this portability problem.
      }
      \li{
        When writing generic code,
        the user should be made aware that accepting \tcode{std::bit_int<N>}
        in a function signature may be problematic.
        For all they know, \tcode{std::bit_int<N>} could have millions of bits,
        and this could make the type too large for passing on the stack.
      }
    }
  }
}

\h2{Implementation experience}

\tcode{_BitInt}, formerly known as \tcode{_ExtInt}, has been a compiler extension
in Clang for several years now.
The core language changes are essentially standardizing that compiler extension.

\h2{Impact on the standard}

\h3{Impact on the core language}

The core language changes essentially boil down to adding the \tcode{_BitInt}
type and the \tcode{wb} \grammarterm{integer-suffix}.
This obviously comes with various syntax changes,
definitions of conversion rank,
addition of template argument deduction rules, etc.
The vast majority of core language wording which deals with integers
is not affected by the existence of bit-precise integers.

\h3{Impact on the standard library}

The impact of adding bit-precise integers to the standard library is quite enormous
because there are many parts of the library
which already support any integer type via blanket wording.

\h3{Broadening "blanket support" of various library components}

Since this proposal does not explicitly remove support for bit-precise integers,
support "sneaks" its way in, without any explicit wording changes.

For example, use of bit-precise integers in \header{simd}, \header{bit}, \header{valarray},
and many others is enabled.

\h4{Broadening the possible definition of type aliases}

The addition of bit-precise integers means that (as in the core language),
the \tcode{size_type} of various containers may be a bit-precise integer,
\tcode{size_t} and \tcode{ptrdiff_t} may be bit-precise integers, etc.

\h4{Broadening (type) traits}

Since bit-precise integer types are integer types,
certain type traits such as \tcode{is_integral} would report \tcode{true} for these new types.
Additionally, \tcode{numeric_limits} specializations for bit-precise integers would be added.

\h4{Bumping various feature-test macros}

Even when support for bit-precise integers is added "silently"
(that is, by leveraging the existing wording which says
that some library part works with all integer types)
it still requires implementation effort in some cases.
For example, proper support for bit-precise integers in \header{bit}
requires some effort,
even if no wording changes are required.
To make support detectable in those cases, various feature-test macros are bumped:

\table{
  \tr{
    \th{Macro}
    \th{Added support}
  }
  \tr{
    \td{\tcode{__cpp_lib_bitops}}
    \td{\tcode{countl_zero} and other bit-manipulation functions}
  }
  \tr{
    \td{\ins{\tcode{__cpp_lib_stdc_bitops}}}
    \td{\header{stdbit.h}}
  }
}

\h2{Wording}

The following changes are relative to \ref(N5014).

\:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

\h3{Core}

\style{
  math[display=inline] {
    font-size: inherit;
  }

  .wording td {
    vertical-align: top;
    border-bottom: 1px solid var(--border-color);
  }

  table.wording code-block {
    margin: 0;
  }
}

\cowel_macro(ins_quotes){\cowel_to_html{\ins{\N{LEFT DOUBLE QUOTATION MARK}}}\cowel_put\cowel_to_html{\ins{\N{RIGHT DOUBLE QUOTATION MARK}}}}
\cowel_macro(bit_int_of_width){\N{LEFT DOUBLE QUOTATION MARK}\tcode{_BitInt} of width \cowel_put\N{RIGHT DOUBLE QUOTATION MARK}}
\cowel_macro(bit_uint_of_width){\N{LEFT DOUBLE QUOTATION MARK}\tcode{unsigned _BitInt} of width \cowel_put\N{RIGHT DOUBLE QUOTATION MARK}}

\Bdecision{
CWG needs to decide what the \q{quoted} (prose)
spelling of bit-precise integer types should be.
The current spelling is e.g. \bit_uint_of_width{\math{\mi{N}}},
which is fairly similar to other code-heavy spellings like \q{\tcode{unsigned int}}.

However, this is questionable because \tcode{_BitInt} is not valid C++ in itself;
\tcode{_BitInt(N)} is.
An alternative would be a pure prose spelling, like
\q{bit-precise unsigned integer of width \math{\mi{N}}},
which is a bit more verbose.

There is no strong author preference.
}

\h4(show-number=false){[lex.icon]}

In \eelis{lex.icon},
change the grammar as follows:

\Bdiff{
\dl(class=grammar){
  \dt{\grammarterm{integer-suffix}:}
  \dd{unsigned-suffix \opt{long-suffix}}
  \dd{unsigned-suffix \opt{long-long-suffix}}
  \dd{unsigned-suffix \opt{size-suffix}}
  \dd{\ins{unsigned-suffix \opt{bit-precise-int-suffix}}}
  \dd{long-suffix \opt{unsigned-suffix}}
  \dd{long-long-suffix \opt{unsigned-suffix}}
  \dd{size-suffix \opt{unsigned-suffix}}
  \dd{\ins{bit-precise-int-suffix \opt{unsigned-suffix}}}
}
\dl(class=grammar){
  \dt{\grammarterm{unsigned-suffix}: one of}
  \dd{\tcode{u} \tcode{U}}
}
\dl(class=grammar){
  \dt{\grammarterm{long-suffix}: one of}
  \dd{\tcode{l} \tcode{L}}
}
\dl(class=grammar){
  \dt{\grammarterm{long-long-suffix}: one of}
  \dd{\tcode{ll} \tcode{LL}}
}
\dl(class=grammar){
  \dt{\grammarterm{size-suffix}: one of}
  \dd{\tcode{z} \tcode{Z}}
}
\dl(class=grammar){
  \dt{\ins{\grammarterm{bit-precise-int-suffix}: one of}}
  \dd{\ins{\tcode{wb} \tcode{WB}}}
}
}

Change table \eelis{tab:lex.icon.type} as follows:

\Bdiff{
\table(class=wording){

  \tr{
    \th{\grammarterm{\nobr{integer-suffix}}}
    \th{\grammarterm{decimal-literal}}
    \th{\grammarterm{integer-literal} other than \grammarterm{decimal-literal}}
  }

  \tr{
    \td{none}
    \td{
      \itemdecl{
\ins_quotes{int}
\ins_quotes{long int}
\ins_quotes{long long int}
}
    }
    \td{
      \itemdecl{
\ins_quotes{int}
\ins_quotes{unsigned int}
\ins_quotes{long int}
\ins_quotes{unsigned long int}
\ins_quotes{long long int}
\ins_quotes{unsigned long long int}
}
    }
  }

  \tr{
    \td{\tcode{u} or \tcode{U}}
    \td{
      \itemdecl{
\ins_quotes{unsigned int}
\ins_quotes{unsigned long int}
\ins_quotes{unsigned long long int}
}
    }
    \td{
      \itemdecl{
\ins_quotes{unsigned int}
\ins_quotes{unsigned long int}
\ins_quotes{unsigned long long int}
}
    }
  }

  \tr{
    \td{\tcode{l} or \tcode{L}}
    \td{
      \itemdecl{
\ins_quotes{long int}
\ins_quotes{long long int}
}
    }
    \td{
      \itemdecl{
\ins_quotes{long int}
\ins_quotes{unsigned long int}
\ins_quotes{long long int}
\ins_quotes{unsigned long long int}
}
    }
  }

  \tr{
    \td{Both \tcode{u} or \tcode{U} and \tcode{l} or \tcode{L}}
    \td{
      \itemdecl{
\ins_quotes{unsigned long int}
\ins_quotes{unsigned long long int}
}
    }
    \td{
      \itemdecl{
\ins_quotes{unsigned long int}
\ins_quotes{unsigned long long int}
}
    }
  }

  \tr{
    \td{Both \tcode{u} or \tcode{U} and \tcode{ll} or \tcode{LL}}
    \td{
      \itemdecl{
\ins_quotes{unsigned long long int}
}
    }
    \td{
      \itemdecl{
\ins_quotes{unsigned long long int}
}
    }
  }

  \tr{
    \td{\tcode{z} or \tcode{Z}}
    \td{
      the signed integer type corresponding to
      \ins{the type named by}
      \tcode{std::size_t}\iref{support.types.layout}
    }
    \td{
      the signed integer type corresponding to
      \ins{the type named by}
      \tcode{std::size_t}\br\br
      \ins{the type named by}
      \tcode{std::size_t}
    }
  }

  \tr{
    \td{Both \tcode{u} or \tcode{U} and \tcode{z} or \tcode{Z}}
    \td{
      \ins{the type named by}
      \tcode{std::size_t}
    }
    \td{
      \ins{the type named by}
      \tcode{std::size_t}
    }
  }
  \tr{
    \td{\ins{\tcode{wb} or \tcode{WB}}}
    \td{
      \ins{\bit_int_of_width{\math{\mi{N}}},
      where \math{\mi{N}} is the lowest integer \math{\mrow{\mo{≥}\mn{1}}}
      so that the value of the literal can be represented by the type}
    }
    \td{
      \ins{\bit_int_of_width{\math{\mi{N}}},
      where \math{\mi{N}} is the lowest integer \math{\mrow{\mo{≥}\mn{1}}}
      so that the value of the literal can be represented by the type}
    }
  }
  \tr{
    \td{
      \ins{Both \tcode{u} or \tcode{U} and\br{}\tcode{wb} or \tcode{WB}}
    }
    \td{
      \ins{\bit_uint_of_width{\math{\mi{N}}},
      where \math{\mi{N}} is the lowest integer \math{\mrow{\mo{≥}\mn{1}}}
      so that the value of the literal can be represented by the type}
    }
    \td{
      \ins{\bit_uint_of_width{\math{\mi{N}}},
      where \math{\mi{N}} is the lowest integer \math{\mrow{\mo{≥}\mn{1}}}
      so that the value of the literal can be represented by the type}
    }
  }
}
}

\Bnote{
The existing rows are adjusted for consistency.
We usually aim to use the \q{quoted} spellings of types
like \bit_int_of_width{\math{\mi{N}}}
in core wording
instead of the \grammarterm{type-id} spellings.
Adding a quoted spelling for bit-precise integers would reveal
that the previous rows "incorrectly" use \grammarterm{type-id}s.
}

Change \eelis{lex.icon#4} as follows:

\Bdiff{
Except for \grammarterm{integer-literal}s containing a \grammarterm{size-suffix}
\ins{or \grammarterm{bit-precise-int-suffix}},
if the value of an \grammarterm{integer-literal} cannot be represented
by any type in its list and an extended integer type\iref{basic.fundamental}
can represent its value,
it may have that extended integer type.
\etc

\note{
An \grammarterm{integer-literal} with a \tcode{z} or \tcode{Z} suffix
is ill-formed if it cannot be represented by \tcode{std::size_t}.
\ins{An \grammarterm{integer-literal} with a \tcode{wb} or \tcode{WB} suffix
is ill-formed if it cannot be represented by any bit-precise integer type
because the necessary width is greater than
\tcode{BITINT_MAXWIDTH}\iref{climits.syn}.}
}
}

\h4(show-number=false){[basic.fundamental]}

Change \eelis{basic.fundamental#1} as follows:

\Bdiff{
There are five \dfn{standard signed integer types}:
\q{\tcode{signed char}},
\q{\tcode{short int}},
\q{\tcode{int}},
\q{\tcode{long int}}, and
\q{\tcode{long long int}}.
In this list,
each type provides at least as much storage as those
preceding it in the list.
\ins{There is also a distinct \dfn{bit-precise signed integer type}
\bit_int_of_width{\math{\mi{N}}}
for each \math{\mrow{\mn{1}\mo{≤}\mi{N}\mo{≤}\mtext{\tt{BITINT_MAXWIDTH}}}}\iref{climits.syn}.}
There may also be implementation-defined
\dfn{extended signed integer types}.
The standard\ins{, bit-precise,} and extended signed integer types are collectively called
\dfn{signed integer types}.
The range of representable values for a signed integer type is
\math{
  \msup{
    \mn{-2}
    \mrow{\mi{N}\mo{−}\mn{1}}
  }
}
to
\math{
  \mrow{
    \msup{
      \mn{2}
      \mrow{\mi{N}\mo{−}\mn{1}}
    }
    \mo{−}
    \mn{1}
  }
}
(inclusive),
where \math{\mi{N}} is called the \dfn{width} of the type.

\note{
Plain \tcode{int}s are intended to have
the natural width suggested by the architecture of the execution environment;
the other signed integer types are provided to meet special needs.
}
}

\Bwarn{
This change deviates from C at the time of writing;
C2y does not yet allow \tcode{_BitInt(1)},
but may allow it following \ref(N3644).
}

Change \eelis{basic.fundamental#2} as follows:

\Bdiff{
For each of the standard signed integer types,
there exists a corresponding (but different)
\dfn{standard unsigned integer type}:
\q{\tcode{unsigned char}},
\q{\tcode{unsigned short}},
\q{\tcode{unsigned int}},
\q{\tcode{unsigned long int}}, and
\q{\tcode{unsigned long long int}}.
\ins{For each bit-precise signed integer type
\bit_int_of_width{\math{\mi{N}}},
there exists a corresponding \dfn{bit-precise unsigned integer type}
\bit_uint_of_width{\math{\mi{N}}}.}
\del{Likewise, for} \ins{For} each of the extended signed integer types,
there exists a corresponding \dfn{extended unsigned integer type}.
The standard\ins{, bit-precise,} and extended unsigned integer types
are collectively called \dfn{unsigned integer types}.
An unsigned integer type has the same width \math{\mi{N}}
as the corresponding signed integer type.
The range of representable values for the unsigned type is
\math{\mn{0}} to
\math{
  \msup{
    \mn{2}
    \mrow{\mi{N}\mo{−}\mn{1}}
  }
} (inclusive);
arithmetic for the unsigned type is performed modulo \math{\msup{\mn{2}\mi{N}}}.

\note{
Unsigned arithmetic does not overflow.
Overflow for signed arithmetic yields undefined behavior\iref{expr.pre}.
}
}

\comment{
Change \eelis{basic.fundamental#4} as follows:

\Bdiff{
The width of each standard signed integer type
shall not be less than the values specified in \tref{basic.fundamental.width}.

The value representation of a signed or unsigned integer type
comprises \math{\mi{N}} bits,
where \math{\mi{N}} is the respective width.
Each set of values for any padding bits\iref{basic.types.general}
in the object representation are
alternative representations of the value specified by the value representation.

\note{
Padding bits have unspecified value, but cannot cause traps.
In contrast, see \IsoC{} 6.2.6.2.
}

\note{
The signed and unsigned integer types satisfy
the constraints given in \IsoC{} 5.2.4.2.1.
}

Except as specified above,
the width of a signed or unsigned integer type is
implementation-defined.
}
}

Change \eelis{basic.fundamental#5} as follows:

\Bdiff{
\etc
The standard signed integer types and standard unsigned integer types
are collectively called the \dfn{standard integer types}\del{, and the}
\ins{. The bit-precise signed integer types and bit-precise unsigned integer types
are collectively called the \dfn{bit-precise integer types}. The}
extended signed integer types and extended
unsigned integer types are collectively called the
\dfn{extended integer types}.
}

\h4(show-number=false){[conv.rank]}

Change \eelis{conv.rank#1} as follows:

\Bdiff{

Every integer type has an \term{integer conversion rank} defined as follows:

\ul{
  \li{
    No two signed integer types other than \tcode{char} and \tcode{signed char}
    (if \keyword{char} is signed) have the same rank, even if they have the same representation.
  }
  \li{
    The rank of a signed integer type is greater than the rank
    of any signed integer type with a smaller width.
  }
  \li{
    The rank of \tcode{long long int} is greater than the rank of \tcode{long int},
    which is greater than the rank of \tcode{int},
    which is greater than the rank of \tcode{short int},
    which is greater than the rank of \tcode{signed char}.
  }
  \li{
    The rank of any unsigned integer type equals the rank of the
    corresponding signed integer type.
  }
  \li{
    The rank of any standard integer type is greater than the rank
    of \ins{any bit-precise integer type with the same width
    and of} any extended integer type with the same width.
  }
  \li{
    The rank of \tcode{char} equals the rank of \tcode{signed char}
    and \tcode{unsigned char}.
  }
  \li{
    The rank of \tcode{bool} is less than the rank of all
    standard integer types.
  }
  \li{
    The ranks of \tcode{char8_t}, \tcode{char16_t}, \tcode{char32_t}, and
    \tcode{wchar_t} equal the ranks of their underlying
    types\iref{basic.fundamental}.
  }
  \li{
    The rank of any extended signed integer type relative to another
    extended signed integer type with the same width
    \ins{and relative to a bit-precise signed integer type with the same width}
    is implementation-defined,
    but still subject to the other rules for determining the integer conversion rank.
  }
  \li{
    For all integer types \tcode{T1}, \tcode{T2}, and \tcode{T3}, if
    \tcode{T1} has greater rank than \tcode{T2} and \tcode{T2} has greater
    rank than \tcode{T3}, then \tcode{T1} has greater rank than
    \tcode{T3}.
  }
}

\note{
The integer conversion rank is used in the definition of the integral
promotions\iref{conv.prom} and the usual arithmetic
conversions\iref{expr.arith.conv}.
}
}

\h4(show-number=false){[conv.prom]}

\Bnote{
These changes mirror the C semantics described in
\ref(N3550) §6.3.2.1 Boolean, characters, and integers.
}

Change \eelis{conv.prom#2} as follows:

\Bdiff{
A prvalue that
\ul{
  \li{is not a converted bit-field \del{and} \ins{,}}
  \li{
    has an integer type other than
    \ins{a bit-precise integer type,}
    \tcode{bool}, \tcode{char8_t}, \tcode{char16_t}, \tcode{char32_t},
    or \tcode{wchar_t}\ins{, and}
  }
  \li{
    whose integer conversion rank\iref{conv.rank}
    is less than the rank of \tcode{int}
  }
}
can be converted to
a prvalue of type \tcode{int}
if \tcode{int} can represent all the values of the source type;
otherwise, the source prvalue can be converted to
a prvalue of type \tcode{unsigned int}.
}

Change \eelis{conv.prom#5} as follows:

\Bdiff{
A converted bit-field of integral type
\ins{other than a bit-precise integer type}
can be converted to a prvalue of type \tcode{int}
if \tcode{int} can represent all the values of the bit-field;
otherwise, it can be converted to \tcode{unsigned int}
if \tcode{unsigned int} can represent all the values of the bit-field.
}

\h4(show-number=false){[dcl.type.general]}

Change \eelis{dcl.type.general#2} as follows:

\Bdiff{
As a general rule,
at most one \grammarterm{defining-type-specifier} is allowed
in the complete \grammarterm{decl-specifier-seq} of a declaration
or in a \grammarterm{defining-type-specifier-seq},
and at most one \grammarterm{type-specifier} is allowed in a \grammarterm{type-specifier-seq}.
The only exceptions to this rule are the following:
\ul{
  \li{\tcode{const} can be combined with any type specifier except itself.}
  \li{\tcode{volatile} can be combined with any type specifier except itself.}
  \li{
    \tcode{signed} or \tcode{unsigned} can be combined with
    \tcode{char}, \tcode{long}, \tcode{short}, \del{or} \tcode{int}\ins{, or
    a \grammarterm{bit-precise-int-type-specifier}.}
  }
  \li{\tcode{short} or \tcode{long} can be combined with \tcode{int}.}
  \li{\tcode{long} can be combined with \tcode{double}.}
  \li{\tcode{long} can be combined with \tcode{long}.}
}
}

\h4(show-number=false){[dcl.type.simple]}

Change \eelis{dcl.type.simple#1} as follows:

\Bdiff{
The simple type specifiers are

\dl(class=grammar){
  \dt{\grammarterm{simple-type-specifier}:}
  \dd{\opt{nested-name-specifier} type-name}
  \dd{nested-name-specifier \tcode{template} simple-template-id}
  \dd{computed-type-specifier}
  \dd{placeholder-type-specifier}
  \dd{\ins{bit-precise-int-type-specifier}}
  \dd{\opt{nested-name-specifier} template-name}
  \dd{\tcode{char}}
  \dd{\tcode{char8_t}}
  \dd{\tcode{char16_t}}
  \dd{\tcode{char32_t}}
  \dd{\tcode{wchar_t}}
  \dd{\tcode{bool}}
  \dd{\tcode{short}}
  \dd{\tcode{int}}
  \dd{\tcode{long}}
  \dd{\tcode{signed}}
  \dd{\tcode{unsigned}}
  \dd{\tcode{float}}
  \dd{\tcode{double}}
  \dd{\tcode{void}}

  \dt{\grammarterm{type-name}:}
  \dd{class-name}
  \dd{enum-name}
  \dd{typedef-name}

  \dt{\grammarterm{computed-type-specifier}:}
  \dd{decltype-specifier}
  \dd{pack-index-specifier}
  \dd{splice-type-specifier}

  \dt{\ins{\grammarterm{bit-precise-int-type-specifier}:}}
  \dd{\ins{\tcode{_BitInt} \tcode{(} constant-expression \tcode{)}}}
}
}

Change table \eelis{tab:dcl.type.simple} as follows:

\cowel_macro(dcl_type_simple_row){\tr{\td{\tcode{\cowel_put{0}}}\td{\q{\tcode{\cowel_put{1}}}}}}

\Bdiff{
  \table{
    \tr{
      \th{Specifier(s)}
      \th{Type}
    }
    \tr{
      \td{\grammarterm{type-name}}
      \td{the type named}
    }
    \tr{
      \td{\grammarterm{simple-template-id}}
      \td{the type as defined in \eelis{temp.names}}
    }
    \tr{
      \td{\grammarterm{decltype-specifier}}
      \td{the type as defined in \eelis{dcl.type.decltype}}
    }
    \tr{
      \td{\grammarterm{pack-index-specifier}}
      \td{the type as defined in \eelis{dcl.type.pack.index}}
    }
    \tr{
      \td{\grammarterm{placeholder-type-specifier}}
      \td{the type as defined in \eelis{dcl.spec.auto}}
    }
    \tr{
      \td{\grammarterm{template-name}}
      \td{the type as defined in \eelis{dcl.type.class.deduct}}
    }
    \tr{
      \td{\grammarterm{splice-type-specifier}}
      \td{the type as defined in \eelis{dcl.type.splice}}
    }
    \tr{
      \td{\ins{\tcode{unsigned _BitInt(\math{\mi{N}})}}}
      \td{\ins{\bit_uint_of_width{\math{\mi{N}}}}}
    }
    \tr{
      \td{\ins{\tcode{signed _BitInt(\math{\mi{N}})}}}
      \td{\ins{\bit_int_of_width{\math{\mi{N}}}}}
    }
    \tr{
      \td{\ins{\tcode{_BitInt(\math{\mi{N}})}}}
      \td{\ins{\bit_int_of_width{\math{\mi{N}}}}}
    }
    \dcl_type_simple_row(char, char)
    \dcl_type_simple_row(unsigned char, unsigned char)
    \dcl_type_simple_row(signed char, signed char)
    \dcl_type_simple_row(char8_t, char8_t)
    \dcl_type_simple_row(char16_t, char16_t)
    \dcl_type_simple_row(char32_t, char32_t)
    \dcl_type_simple_row(bool, bool)
    \dcl_type_simple_row(unsigned, unsigned int)
    \dcl_type_simple_row(unsigned int, unsigned int)
    \dcl_type_simple_row(signed, int)
    \dcl_type_simple_row(signed int, int)
    \dcl_type_simple_row(int, int)
    \dcl_type_simple_row(unsigned short int, unsigned short int)
    \dcl_type_simple_row(unsigned short, unsigned short int)
    \dcl_type_simple_row(unsigned long int, unsigned long int)
    \dcl_type_simple_row(unsigned long, unsigned long int)
    \dcl_type_simple_row(unsigned long long int, unsigned long long int)
    \dcl_type_simple_row(unsigned long long, unsigned long long int)
    \dcl_type_simple_row(signed long int, long int)
    \dcl_type_simple_row(signed long, long int)
    \dcl_type_simple_row(signed long long int, long long int)
    \dcl_type_simple_row(signed long long, long long int)
    \dcl_type_simple_row(long long int, long long int)
    \dcl_type_simple_row(long long, long long int)
    \dcl_type_simple_row(long int, long int)
    \dcl_type_simple_row(long, long int)
    \dcl_type_simple_row(signed short int, short int)
    \dcl_type_simple_row(signed short, short int)
    \dcl_type_simple_row(short int, short int)
    \dcl_type_simple_row(short, short int)
    \dcl_type_simple_row(wchar_t, wchar_t)
    \dcl_type_simple_row(float, float)
    \dcl_type_simple_row(double, double)
    \dcl_type_simple_row(long double, long double)
    \dcl_type_simple_row(void, void)
  }
}

Immediately following \eelis{dcl.type.simple#3},
add a new paragraph as follows:

\Bins{
Within a \grammarterm{bit-precise-int-type-specifier},
the \grammarterm{constant-expression} shall be a converted constant expression of type
\tcode{std::size_t}\iref{expr.const}.
Its value \math{\mi{N}} specifies the width
of the bit-precise integer type\iref{basic.fundamental}.
The program is ill-formed unless
\math{
  \mrow{
    \mn{1}
    \mo{≤}
    \mi{N}
    \mo{≤}
    \mtext{\tt{BITINT_MAXWIDTH}}
  }
}\iref{climits.syn}.
}

\h4(show-number=false){[dcl.enum]}

\Bnote{
The intent is to ban \tcode{_BitInt} from being the underlying type of enumerations,
matching the current restrictions in C.
See \ref(#underlying-bitint).
}

Change \eelis{dcl.enum#2} as follows:

\Bdiff{
\etc
The \grammarterm{type-specifier-seq} of an \grammarterm{enum-base}
shall name an integral type
\ins{other than a bit-precise integer type};
any cv-qualification is ignored.
\etc
}

Change \eelis{dcl.enum#5} as follows:

\Bdiff{
\etc
If the underlying type is not fixed,
the type of each enumerator prior ot the closing brace is determined as follows:

\ul{
  \li{
    If an initializer is specified for an enumerator,
    the \grammarterm{constant-expression} shall be
    an integral constant expression\iref{expr.const}
    \ins{whose type is not a bit-precise integer type}.
    If the expression has unscoped enumeration type,
    the enumerator has the underlying type of that enumeration type,
    otherwise it has the same type as the expression.
  }
  \li{
    If no initializer is specified for the first enumerator,
    its type is an unspecified signed \del{integral} \ins{integer} type
    \ins{other than a bit-precise integer type}.
  }
  \li{
    Otherwise\ins{,} the type of the enumerator is the same as
    that of the preceding enumerator\ins{,}
    unless the incremented value is not representable in that type,
    in which case the type is an unspecified integral type
    \ins{other than a bit-precise integer type}
    sufficient to contain the incremented value.
    If no such type exists, the program is ill-formed.
  }
}
}

Change \eelis{dcl.enum#7} as follows:

\Bdiff{
For an enumeration whose underlying type is not fixed,
the underlying type is an integral type
that can represent all the enumerator values defined in the enumeration.
If no integral type can represent all the enumerator values,
the enumeration is ill-formed.
It is implementation-defined which integral type is used as the underlying type\ins{,}
except that
\ul{
  \li{
    \ins{the underlying type shall not be a bit-precise integer type and}
  }
  \li{
    the underlying type shall not be larger than \tcode{int}
    unless the value of an enumerator
    cannot fit in an \tcode{int} or \tcode{unsigned int}.
  }
}
If the \grammarterm{enumerator-list} is empty,
the underlying type is as if the enumeration had a single enumerator with value 0.
}

\h4(show-number=false){[temp.deduct.general]}

Add a bullet to \eelis{temp.deduct.general#note-8} as follows:

\Bdiff{
\note{
Type deduction can fail for the following reasons:

\ul{
  \li{Attempting to instantiate a pack expansion containing multiple packs of differing lengths.}
  \li{
    Attempting to create an array with an element type that is \tcode{void},
    a function type, or a reference type,
    or attempting to create an array with a size that is zero or negative.
    \br\example{
    \itemdecl{
template <class T> int f(T[5]);
int I = f<int>(0);
int j = f<void>(0);             // \serif{invalid array}
}
    }
  }
  \li{
    \ins{Attempting to create a bit-precise integer type of invalid width\iref{basic.fundamental}.
    \br\example{
    \itemdecl{
\ins{template <int N> void f(_BitInt(N));
f<0>(0);                        // \serif{invalid bit-precise integer}}
}
    }
    }
  }
  \li{\etc}
}
}
}

\h4(show-number=false){[temp.deduct.type]}

Change \eelis{temp.deduct.type#2} as follows:

\Bdiff{
\etc
The type of a type parameter is only deduced from an array bound
\ins{or bit-precise integer width}
if it is not otherwise deduced.
}

Change \eelis{temp.deduct.type#3} as follows:

\Bdiff{
A given type \tcode{P} can be composed from a number of other types,
templates, and constant template argument values:
\ul{
  \li{
    A function type includes the types of each of the function parameters,
    the return type, and its exception specification.
  }
  \li{
    A pointer-to-member type includes the type of the class object pointed to
    and the type of the member pointed to.
  }
  \li{
    A type that is a specialization of a class template (e.g., \tcode{A<int>}) includes the types,
    templates, and constant template argument values
    referenced by the template argument list of the specialization.
  }
  \li{
    An array type includes the array element type and the value of the array bound.
  }
  \li{
    \ins{A bit-precise integer type includes the integer width.}
  }
}
}

Change \eelis{temp.deduct.type#5} as follows:

\Bdiff{
The non-deduced contexts are:
\ul{
  \li{\etc}
  \li{
    A constant template argument \del{or} \ins{,} an array bound\ins{, or
    a bit-precise integer width,}
    in \ins{any of} which a subexpression references a template parameter.
    \br\ins{\example{
    \itemdecl{
\ins{template<size_t N> void f(_BitInt(N));
template<size_t N> void g(_BitInt(N + 1));
f(100wb);                                   // \serif{OK}, \tcode{N = 8}
g(100wb);                                   // \serif{error: no argument for deduced \tcode{N}}}
}
    }}
  }
  \li{\etc}
}
}

Change \eelis{temp.deduct.type#8} as follows:

\Bdiff{
A type template argument \tcode{T},
a constant template argument \tcode{i},
a template template argument \tcode{TT} denoting a class template or an alias template,
or a template template argument \tcode{VV} denoting a variable template or a concept
can be deduced if \tcode{P} and \tcode{A} have one of the following forms:

\itemdecl{
\opt{\cv} T
T*
T&
T&&
\opt{T}[\opt{i}]
\ins{_BitInt(\opt{i})}
\opt{T}(\opt{T}) noexcept(\opt{i})
\opt{T} \opt{T}::*
\opt{TT}<T>
\opt{TT}<i>
\opt{TT}<TT>
\opt{TT}<VV>
\opt{TT}<>
}

where \etc
}

Do \u{not} change \eelis{temp.deduct.type#14}; it is included here for reference.

\Bquote{
The type of \tt{N} in the type \tt{T[N] is \tt{std::size_t}}.

\example{
\codeblock(text, borders=false){
template<typename T> struct S;
template<typename T, T n> struct S<int[n]> {
  using Q = T;
};

using V = decltype(sizeof 0);
using V = S<int[42]>::Q;        // \serif{OK; \tt{T} was deduced as \tt{std::size_t} from the type \tt{int[42]}}
}
}
}

Immediately following \eelis{temp.deduct.type#14}, insert a new paragraph:

\Bins{
The type of \tcode{N} in the type \tcode{_BitInt(N)} is \tcode{std::size_t}.

\example{
\itemdecl{
template <typename T, T n> void f(_BitInt(n));

f(0wb);                         // \serif{OK; \tcode{T} was deduced as \tcode{std::size_t} from an argument of type \tcode{_BitInt(1)}}
}
}
}

Change \eelis{temp.deduct.type#20} as follows:

\Bdiff{
If \tcode{P} has a form that contains \tcode{<i>},
and if the type of \tcode{i} differs from the type of the corresponding template parameter
of the template named by the enclosing \grammarterm{simple-template-id}
or \grammarterm{splice-specialization-specifier}, deduction fails.
If \tcode{P} has a form that contains \tcode{[i]}
\ins{or \tcode{_BitInt(i)}},
and if the type of \tcode{i} is not an integral type, deduction fails.
If \tcode{P} has a form that includes \tcode{noexcept(i)}
and the type of \tcode{i} is not \tcode{bool}, deduction fails.
}

\h4(show-number=false){[cpp.predefined]}

Add a feature-test macro to the table in \eelis{cpp.predefined} as follows:

\Bins{
\itemdecl{
__cpp_bit_int 20XXXXL
}
}

\h3{Library}

\h4(show-number=false){[cstdint.syn]}

In \eelis{cstdint.syn},
update the header synopsis as follows:

\Bdiff{
\itemdecl{
namespace std {
  \etc

  using uintmax_t = \exposid{unsigned integer type};
  using uintptr_t = \exposid{unsigned integer type}; // \serif{optional}

\ins{  template<size_t N>
    using bit_int = _BitInt(N);
  template<size_t N>
    using bit_uint = unsigned _BitInt(N);}
}
}
}

Change \eelis{cstdint.syn#2} as follows:

\Bdiff{
The header defines all types and macros the same as the C standard library header \tt{<stdint.h>}.
\ins{None of the aliases name a bit-precise integer type.}
The types denoted by \tcode{intmax_t} and \tcode{uintmax_t}
are not required to be able to represent all values of
\ins{bit-precise integer types or of}
extended integer types wider than
\tcode{\ins_quotes{long long \ins{int}}} and
\tcode{\ins_quotes{unsigned long long \ins{int}}},
respectively.
}

Change \eelis{cstdint.syn#3} as follows:

\Bdiff{
All types that use the placeholder \placeholder{N}
are optional when \placeholder{N}
is not \tcode{8}, \tcode{16}, \tcode{32}, or \tcode{64}.
The exact-width types
\tcode{int\placeholdernc{N}_t} and \tcode{uint\placeholdernc{N}_t}
for \placeholder{N} = \tcode{8}, \tcode{16}, \tcode{32}, and \tcode{64}
are also optional;
however, if an implementation defines integer types
\ins{other than bit-precise integer types}
with the corresponding width and no padding bits,
it defines the corresponding \grammarterm{typedef-name}s.
Each of the macros listed in this subclause
is defined if and only if
the implementation defines the corresponding \grammarterm{typedef-name}.
\br\note{
The macros \tcode{INT\placeholdernc{N}_C} and \tcode{UINT\placeholdernc{N}_C}
correspond to the \grammarterm{typedef-name}s
\tcode{int_least\placeholdernc{N}_t} and \tcode{uint_least\placeholdernc{N}_t},
respectively.
}
}

\h4(show-number=false){[climits.syn]}

In \eelis{climits.syn},
add a new line below the definition of \tcode{\hl(macro){ULLONG_WIDTH}}:

\Bins{
\itemdecl{
#define BITINT_MAXWIDTH \exposid{see below}
}
}

Change the synopsis in \eelis{climits.syn#1} as follows:

\Bdiff{
The header \tt{<climits>} defines all macros
the same as the C standard library header \tt{limits.h}\del{,
except that it does not define the macro \tcode{BITINT_MAXWIDTH}}.
}

\h4(show-number=false){[stdbit.h.syn]}

Change \eelis{stdbit.h.syn#2} as follows:

\Bdiff{
\mandates
\tcode{T} is \del{an unsigned integer type}
\ul{
  \li{\ins{a standard unsigned integer type,}}
  \li{\ins{an extended unsigned integer type, or}}
  \li{
    \ins{a bit-precise unsigned integer type whose width matches
    a standard or extended integer type}.
  }
}
}

\h4(show-number=false, id=wording-iota-view){[range.iota.view]}

\Bnote{See \ref(#preventing-iota-view-abi-break).}

Change \eelis{range.iota.view#1} as follows:

\Bdiff{
Let \tcode{\exposid{IOTA-DIFF-T}(W)} be defined as follows:

\ul{
  \li{
    If \tcode{W} is not an integral type,
    or if it is an integral type and \tcode{sizeof(iter_difference_t<W>)} is
    greater than \tcode{sizeof(W)},
    then \tcode{\exposid{IOTA-DIFF-T}(W)} denotes \tcode{iter_difference_t<W>}.
  }
  \li{
    Otherwise, \tcode{\exposid{IOTA-DIFF-T}(W)}
    is a \ins{standard} signed integer type of width greater than the width of \tcode{W}
    if such a type exists.
  }
  \li{
    Otherwise, \tcode{\exposid{IOTA-DIFF-T}(W)}
    is an unspecified signed-integer-like\iref{iterator.concept.winc} type
    of width not less than the width of \tcode{W}.
  }
}
}

\h4(show-number=false){[alg.foreach]}

Change \eelis{alg.foreach#lib:for_each_n} as follows:

\Bdiff{
\itemdecl{
template<class InputIterator, class Size, class Function>
  constexpr InputIterator for_each_n(InputIterator first, Size n, Function f);
}

\itemdescr{
\mandates
The type \tcode{Size} is convertible to an integral type
\ins{other than a bit-precise integer type}
(\eelis{conv.integral}, \eelis{class.conv}).

\etc
}

\itemdecl{
template<class ExecutionPolicy, class ForwardIterator, class Size, class Function>
  ForwardIterator for_each_n(ExecutionPolicy&& exec, ForwardIterator first, Size n,
                             Function f);
}

\itemdescr{
\mandates
The type \tcode{Size} is convertible to an integral type
\ins{other than a bit-precise integer type}
(\eelis{conv.integral}, \eelis{class.conv}).

\etc
}
}

\Bnote{
Implementing this requirement for bit-precise integer types is generally impossible,
barring compiler magic.
The libc++ implementation is done by calling an overload in the set:

\cppblock{
int __convert_to_integral(int __val) { return __val; }
unsigned __convert_to_integral(unsigned __val) { return __val; }
}

It is not reasonable to expect millions of additional overloads,
and a template that can handle bit-precise integers in bulk could not interoperate with
user-defined conversion function templates.
}

\h4(show-number=false){[alg.search]}

Change \eelis{alg.search#5} as follows:

\Bdiff{
\mandates
The type \tcode{Size} is convertible to an integral type
\ins{other than a bit-precise integer type}
(\eelis{conv.integral}, \eelis{class.conv}).
}

\h4(show-number=false){[alg.copy]}

Change \eelis{alg.copy#15} as follows:

\Bdiff{
\mandates
The type \tcode{Size} is convertible to an integral type
\ins{other than a bit-precise integer type}
(\eelis{conv.integral}, \eelis{class.conv}).
}

\h4(show-number=false){[alg.fill]}

Change \eelis{alg.fill#2} as follows:

\Bdiff{
\mandates
The expression \tcode{value} is writable\iref{iterator.requirements.general}
to the output iterator.
The type \tcode{Size} is convertible to an integral type
\ins{other than a bit-precise integer type}
(\eelis{conv.integral}, \eelis{class.conv}).
}

\h4(show-number=false){[alg.generate]}

Change \eelis{alg.generate#2} as follows:

\Bdiff{
\mandates
\tcode{Size} is convertible to an integral type
\ins{other than a bit-precise integer type}
(\eelis{conv.integral}, \eelis{class.conv}).
}

\h4(show-number=false){[charconv.syn]}

Change \eelis{charconv.syn#1} as follows:

\Bdiff{
When a function is specified with a type placeholder of \tcode{\exposid{integer-type}},
the implementation provides overloads for \tcode{char}
and all \del{cv-unqualified signed and unsigned integer types}
\ins{standard and extended integer types}
in lieu of \tcode{\exposid{integer-type}}.
When a function is specified with a type placeholder of \tcode{\exposid{floating-point-type}},
the implementation provides overloads for all
cv-unqualified floating-point types\iref{basic.fundamental}
in lieu of \tcode{\exposid{floating-point-type}}.

\itemdecl{
namespace std {
  // \serif{floating-point format for primitive numerical conversion}
  enum class chars_format {
    scientific = unspecified,
    fixed = unspecified,
    hex = unspecified,
    general = fixed | scientific
  };

  // \serif{[charconv.to.chars], primitive numerical output conversion}
  struct to_chars_result {                                              // \serif{freestanding}
    char* ptr;
    errc ec;
    friend bool operator==(const to_chars_result&, const to_chars_result&) = default;
    constexpr explicit operator bool() const noexcept { return ec == errc{}; }
  };

  constexpr to_chars_result to_chars(char* first, char* last,           // \serif{freestanding}
                                     \exposid{integer-type} value, int base = 10);
\ins{  template<class T>
    constexpr to_chars_result to_chars(char* first, char* last,         // \serif{freestanding}
                                       T value, int base = 10);}
  to_chars_result to_chars(char* first, char* last,                     // \serif{freestanding}
                           bool value, int base = 10) = delete;

  to_chars_result to_chars(char* first, char* last,                     // \serif{freestanding-deleted}
                           \exposid{floating-point-type} value);
  to_chars_result to_chars(char* first, char* last,                     // \serif{freestanding-deleted}
                           \exposid{floating-point-type} value, chars_format fmt);
  to_chars_result to_chars(char* first, char* last,                     // \serif{freestanding-deleted}
                           \exposid{floating-point-type} value, chars_format fmt, int precision);

  // \serif{[charconv.from.chars], primitive numerical input conversion}
  struct from_chars_result {                                            // \serif{freestanding}
    const char* ptr;
    errc ec;
    friend bool operator==(const from_chars_result&, const from_chars_result&) = default;
    constexpr explicit operator bool() const noexcept { return ec == errc{}; }
  };

  constexpr from_chars_result from_chars(const char* first, const char* last,   // \serif{freestanding}
                                         \exposid{integer-type}& value, int base = 10);
\ins{  template<class T>
    constexpr to_chars_result to_chars(char* first, char* last,         // \serif{freestanding}
                                       T& value, int base = 10);}

  from_chars_result from_chars(const char* first, const char* last,     // \serif{freestanding-deleted}
                               \exposid{floating-point-type}& value,
                               chars_format fmt = chars_format::general);
}
}
}

\h4(show-number=false){[charconv.to.chars]}

Change \eelis{charconv.to.chars} as follows:

\Bdiff{
\etc

\itemdecl{
constexpr to_chars_result to_chars(char* first, char* last, \exposid{integer-type} value, int base = 10);
\ins{template<class T>
  constexpr to_chars_result to_chars(char* first, char* last, T value, int base = 10);}
}

\itemdescr{
\ins{\constraints
\tcode{T} is a bit-precise integer type.}

\expects
\tcode{base} has a value between 2 and 36 (inclusive).
}

\etc
}

\h4(show-number=false){[charconv.from.chars]}

Change \eelis{charconv.from.chars} as follows:

\Bdiff{
\etc

\itemdecl{
constexpr from_chars_result from_chars(const char* first, const char* last,
                                       \exposid{integer-type}& value, int base = 10);
\ins{template<class T>
  constexpr from_chars_result from_chars(const char* first, const char* last,
                                         T& value, int base = 10);}
}

\itemdescr{
\ins{\constraints
\tcode{T} is a bit-precise integer type.}

\expects
\tcode{base} has a value between 2 and 36 (inclusive).
}

\etc
}

\h4(show-number=false){[cmath.syn]}

In \eelis{cmath.syn}, change the synopsis as follows:

\Bdiff{
\itemdecl{
constexpr int abs(int j);                                         // \serif{freestanding}
constexpr long int abs(long int j);                               // \serif{freestanding}
constexpr long long int abs(long long int j);                     // \serif{freestanding}
\ins{template<size_t N> constexpr abs(bit_int<N> j);                   // \serif{freestanding}}
constexpr \exposid{floating-point-type} abs(\exposid{floating-point-type} j);         // \serif{freestanding}
}
}

\Bnote{
Simply specifying the whole overload set as a \tcode{template<class T> abs(T);}
function would be a breaking change because it would no longer support types
that are convertible to \tcode{int} but are not signed integer types.
}

Change \eelis{cmath.syn#3} as follows:

\Bdiff{
For each function with at least one parameter of type \tcode{\exposid{floating-point-type}}
other than \tcode{abs},
the implementation also provides additional overloads sufficient to ensure that,
if every argument corresponding to a \tcode{\exposid{floating-point-type}} parameter
has arithmetic type
\ins{other than \cv bit-precise integer type},
then every such argument is effectively cast to the floating-point type
with the greatest floating-point conversion rank
and greatest floating-point conversion subrank among the types of all such arguments,
where arguments of integer type are considered to have
the same floating-point conversion rank as double.
If no such floating-point type with the greatest rank and subrank exists,
then overload resolution does not result in a usable candidate\iref{over.match.general}
from the overloads provided by the implementation.
}

\h4(show-number=false){[c.math.abs]}

Change \eelis{c.math.abs} as follows:

\Bdiff{
\itemdecl{
constexpr int abs(int j);
constexpr long int abs(long int j);
constexpr long long int abs(long long int j);
\ins{template<size_t N> constexpr abs(bit_int<N> j);}
}

\del{\effects
These functions have the semantics specified in the C standard library for the functions
\tcode{abs}, \tcode{labs}, and \tcode{llabs}, respectively.}

\del{\remarks
If \tcode{abs} is called with an argument of type \tcode{X}
for which \tcode{is_unsigned_v<X>} is \tcode{true}
and if \tcode{X} cannot be converted to \tcode{int} by integral promotion,
the program is ill-formed.
\br\note{
Allowing arguments that can be promoted to \tcode{int} provides compatibility with C.
}}

\ins{\effects
Equivalent to \tcode{j >= 0 ? j : -j}.
\br\note{The behavior is undefined if \tcode{j}
has the lowest possible integer value of its type\iref{expr.pre}.}}
}

\Bnote{
Specifying the undefined behavior as a \i{Preconditions} specification
would be worse because it may cause library UB during constant evaluation.

The \i{Effects} specification needs to be altered because \tcode{abs}
for bit-precise integers is a novel invention with no C counterpart.
It also seems like unnecessary indirection to refer to another language standard
for a single expression.

The \i{Remarks} specification is removed
because is a usage tutorial and history lesson;
it does not say anything about what \tcode{abs} does.
The specification is also factually wrong.
Just because an attempt is made to call \tcode{abs(0u)} and the overloads above
don't handle it,
doesn't mean that the user doesn't have their own
\tcode{abs(unsigned)} overload.
In that event, the program is not ill-formed;
overload resolution simply doesn't select one of these functions.
}

\Btodo{
Add a feature-test macro for these changes.
}

\h4(show-number=false){[numerics.c.ckdint]}

Change \eelis{numerics.c.ckdint} as follows:

\Bdiff{
\itemdecl{
template<class type1, class type2, class type3>
  bool ckd_add(type1* result, type2 a, type3 b);
template<class type1, class type2, class type3>
  bool ckd_sub(type1* result, type2 a, type3 b);
template<class type1, class type2, class type3>
  bool ckd_mul(type1* result, type2 a, type3 b);
}

\mandates
\ins{\tcode{type1} is a signed or unsigned integer type.}
Each of the types \del{\tcode{type1},}
\tcode{type2}\del{,} and \tcode{type3}
is a \del{cv-unqualified} signed or unsigned integer type
\ins{other than a bit-precise integer type}.

\remarks
Each function template has the same semantics
as the corresponding type-generic macro with the same name
specified in \IsoC, 7.20.
}

\Bnote{
This matches the restrictions in \ref(N3550), 7.20 "Checked Integer Arithmetic".
"cv-unqualified" is struck because it is redundant.
}

\h4(show-number=false){[atomics.ref.int]}

Do \u{not} change \eelis{atomics.ref.int#1};
it is provided here for reference:

\Bquote{
There are specializations of the \tcode{atomic_ref} class template
for all integral types except \cv \tcode{bool}.
For each such type \tcode{\exposid{integral-type}},
the specialization \tcode{atomic_ref<\exposid{integral-type}>}
provides additional atomic operations
appropriate to integral types.
}

\h4(show-number=false){[atomics.types.int]}

Change \eelis{atomics.types.int#1} as follows:

\Bdiff{
There are specializations of the \tcode{atomic} class template for
\del{the integral types
\tcode{char},
\tcode{signed char},
\tcode{unsigned char},
\tcode{short},
\tcode{unsigned short},
\tcode{int},
\tcode{unsigned int},
\tcode{long},
\tcode{unsigned long},
\tcode{long long},
\tcode{unsigned long long},
\tcode{char8_t},
\tcode{char16_t},
\tcode{char32_t},
\tcode{wchar_t},}
\ins{standard integer types,
bit-precise integer types,
character types,}
and any other types needed by the typedefs
in the header \tt{<cstdint>}\iref{cstdint.syn}.
For each such type \tcode{\exposid{integral-type}},
the specialization \tcode{atomic<\exposid{integral-type}>}
provides additional atomic operations
appropriate to integral types.

\note{
The specialization \tcode{atomic<bool>}
uses the primary template\iref{atomics.types.generic}.
}
}

\h2{Acknowledgements}

I thank Jens Maurer and Christof Meerwald
for reviewing and correcting the proposal's wording.

I thank Erich Keane and other LLVM contributors
for implementing most of the proposed core changes in Clang's C++ frontend,
giving this paper years worth of implementation experience in a major compiler
without any effort by the author.

I thank
Erich Keane,
Bill Seymour,
Howard Hinnant,
JeanHeyd Meneide,
Lénárd Szolnoki,
Brian Bi,
Peter Dimov,
Aaron Ballman,
Pete Becker,
Jens Maurer,
Matthias Kretz,
Jonathan Wakely,
and \em{many} others for providing early feedback on this paper,
prior papers such as \ref(P3639R0), and
the discussion surrounding bit-precise integers as a whole.
The paper would not be where it is today without \em{hundreds}
of messages worth of valuable feedback.

\h2{References}

\bib(
  id = N5014,
  title = Working Draft\, Programming Languages — C++,
  date = 2025-08-05,
  author = Thomas Köppe,
  link = https://wg21.link/n5014,
  long-link = https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2025/n5014.pdf
)\
\bib(
  id = P3140R0,
  title = std::int_least128_t,
  date = 2025-02-11,
  author = Jan Schultke,
  link = https://wg21.link/p3140r0,
  long-link = https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3140r0.html,
)\
\bib(
  id = P3639R0,
  title = The _BitInt Debate,
  date = 2025-02-20,
  author = Jan Schultke,
  link = https://wg21.link/p3639r0,
  long-link = https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2025/p3639r0.html
)\
\bib(
  id = P3312R1,
  title = Overload Set Types,
  date = 2025-04-16,
  author = Bengt Gustafsson,
  link = https://wg21.link/p3312r1,
  long-link = https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2025/p3312r1.pdf
)\
\bib(
  id = N2763,
  title = Adding a Fundamental Type for N-bit integers,
  date = 2021-06-21,
  author = Aaron Ballman\, Melanie Blower\, Tommy Hoffner\, Erich Keane,
  link = https://open-std.org/JTC1/SC22/WG14/www/docs/n2763.pdf
)\
\bib(
  id = N2775,
  title = Literal suffixes for bit-precise integers,
  date = 2021-07-13,
  author = Aaron Ballman\, Melanie Blower,
  link = https://open-std.org/JTC1/SC22/WG14/www/docs/n2775.pdf
)\
\bib(
  id = N3550,
  title = ISO/IEC 9899:202y (en) — N3550 working draft,
  date = 2025-05-04,
  author = JeanHeyd Meneide,
  link = https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3550.pdf,
)\
\bib(
  id = N3644,
  title = Integer Sets\, v2,
  date = 2025-07-05,
  author = Robert C. Seacord,
  link = https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3644.pdf,
)\

\make_bib
