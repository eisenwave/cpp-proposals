\cowel_include{libwg21.cow}

\wg21_head(
  title = Deprecate implicit conversions
          between \tt{char8_t} and \tt{char16_t}\, \tt{char32_t}\, or \tt{wchar_t}
){
\dl{
  \dt{Document number:} \dd{\docnum{P3695R2}}
  \dt{Date:}            \dd{\tt{2025-09-28}}
  \dt{Audience:}        \dd{EWG, SG16}
  \dt{Project:}         \dd{ISO/IEC 14882 Programming Languages — C++, ISO/IEC JTC1/SC22/WG21}
  \dt{Author:}          \dd{Jan Schultke <\mail{janschultke@gmail.com}>}
  \dt{GitHub Issue:}    \dd{\ref(https://wg21.link/P3695/github)}
  \dt{Source:}          \dd{\ref(https://github.com/Eisenwave/cpp-proposals/blob/master/src/deprecate-unicode-conversion.cow)}
}
\hr
}

\Babstract{
Implicit conversions between \tcode{char8_t}
and \tcode{char16_t}, \tcode{char32_t}, or \tcode{wchar_t}
are bug-prone and thus harmful to the language.
I propose to deprecate them.
}

\h2(listed=false){Contents}

\make_contents

\h2{Revision history}

\h3{Changes since R1}

R0 of the paper was seen by SG16, with the following poll results:

\Bquote{
\b{P3695R1: Recommend deprecating conversions between char and the charN_t types.}
\ul{
  \li{Attendees: 10}
  \li{No objection to unanimous \b{dissent}.}
}

\b{P3695R1: Recommend deprecating conversions between char8_t and wchar_t.}
\ul{
  \li{Attendees: 10}
  \li{No objection to unanimous consent.}
}

\b{P3695R1: Recommend deprecating conversions between char16_t and char32_t.}
\ul{
  \li{Attendees: 10}
  \li{\five_way_poll(0,0,3,7,0)}
  \li{Consensus against.}
}
}

Consequently, the following changes were made:

\ul{
  \li{
    also deprecated conversion between \tcode{char8_t} and \tcode{wchar_t};
    see \ref(#char-and-wchar_t)
  }
  \li{changed title and abstract to reflect this new direction}
  \li{rewrote \ref(#char16_t-char32_t)}
  \li{expanded note on tautology warnings in \ref(#this-really-happens)}
  \li{added \ref(#narrowing-conversions)}
  \li{restructured \ref(#wording) and added editorial notes}
}

\h3{Changes since R0}

\ul{
  \li{
    limited deprecation to conversions involving \tcode{char8_t};
    see \ref(#char16_t-char32_t)
  }
  \li{rebased \ref(#wording) on \ref(N5014)}
}

\h2{Introduction}

Implicit conversions between \tcode{char8_t} and \tcode{char32_t} invite bugs:

\Bug{
Until \em{very} recently, no major compiler would detect the following "bad comparison":
\cppblock{
constexpr bool contains_oe(std::u8string_view str) {
    for (char8_t c : str)
        if (c == U'ö')
            return true;
    return false;
}
static_assert(contains_oe(u8"ö")); // fails?!
}
\tcode{c == U'ö'} always fails if \tcode{c} is a UTF-8 code unit
because it is equivalent to \tcode{c == char32_t(0xf6)},
and a UTF-8 code unit cannot have this value.
}

\Bug{
An even more evil variation is a search which yields false positives:
\cppblock{
constexpr bool contains_nbsp(std::u8string_view str) {
    for (char8_t c : str)
        if (c == U'\\N{NO-BREAK SPACE}')
            return true;
    return false;
}
static_assert(contains_nbsp(u8"\\N{CYRILLIC CAPITAL LETTER EL WITH MIDDLE HOOK}")); // OK?!
}
The assertion succeeds because Ԡ (U+0520) is UTF-8 encoded as \tcode{0xd4}, \tcode{0xa0},
and NBSP is U+00A0,
so the \tcode{char32_t(0xa0)} value matches the second UTF-8 code unit of U+0520.
}

\Bug{
Such bad comparisons often don't occur directly, but within \header{algorithm}:
\cppblock{
constexpr bool is_umlaut(char32_t c) {
    return c == U'ä' || c == U'ö' || c == U'ü';
}
// ...
constexpr std::u8string_view umlauts = u8"äöü";
static_assert(std::ranges::find_if(umlauts, is_umlaut) != umlauts.end()); // fails?!
}
Note that the "bad comparison" occurs between two \tcode{char32_t} in \tcode{is_umlaut},
which demonstrates that implicit conversions in general are bug-prone, not just comparisons.
We obviously don't want to deprecate \tcode{char32_t == char32_t}.
}

Conversions "the other way" (e.g. \tcode{char32_t} → \tcode{char8_t})
are obviously bug-prone too because information is lost,
but such bugs can already be caught by all major compilers' warnings,
and they are problematic for the same reason as \tcode{int} → \tcode{short},
not because of anything specific to character types.
The listed bugs are interesting \em{precisely because} no information is lost.

\h3(id=this-really-happens){It's not hypothetical. This really happens.}

These kinds of bugs are not far-fetched hypotheticals either;
I have written such bugs myself,
and have had them contributed
to my syntax highlighter \ref(µlight),
which makes extensive use of \tcode{char8_t} and \tcode{char32_t}.
Very early in development, I have realized how dangerous these implicit conversions are,
so most functions in the style of \tcode{is_umlaut} have a deleted overload:
\cppblock{
constexpr bool is_umlaut(char8_t) = delete;
constexpr bool is_umlaut(char32_t c) {
    return c == U'ä' || c == U'ö' || c == U'ü';
}
}

\Bnote{
Compilers do have warnings which detect comparisons which are always \tcode{false},
but technically, \tcode{char8_t} can have the values \tcode{0xf6} and \tcode{0xa0},
so it is undetectable.

Using \tcode{char} may raise more tautology warnings because if \tcode{char} is signed,
it can only hold values up to \tcode{127},
meaning it never compares equal to, e.g. \tcode{0xa0}.
}

\h3{The underlying problem}

The underlying problem is that \tcode{char8_t == char32_t} is \tcode{Car == Banana}.
In general, it is meaningless to compare code units with different encodings.

To be fair, Unicode character types aren't strictly required to store Unicode code units.
However, that is their primary purpose, and the assumption holds true for any Unicode
\grammarterm{character-literal} and \grammarterm{string-literal}.

\h2{Scope}

I propose to deprecate implicit conversions between
\tcode{char8_t} and \tcode{char16_t}, \tcode{char32_t}, or \tcode{wchar_t}.
As demonstrated above, these are extremely bug-prone.
Conversions between \tcode{char16_t} and \tcode{char32_t} are not affected.

\h3(id=safe-comparisons){What about "safe" comparisons?}

In comparisons between code units,
certain ranges of code points yield the expected result.
For example, \tcode{u8'x' == U'x'} is \tcode{true}
because all Unicode encodings are ASCII-compatible,
so the numeric value of anything in the basic latin block (≤ U+007F)
will have the same single-code-unit value in UTF-8, UTF-16, and UTF-32.

However, even those should be deprecated because:
\ul{
  \li{
    Keeping these valid would essentially leak implementation details of UTF-8
    into the set of implicit conversions in the C++ core language,
    which seems like unclean design.
  }
  \li{
    To rely on this "feature", the developer needs to memorize which code points are "safe to use".
    It is not obvious whether \tcode{c == U'€'} or \tcode{c == U'\N{DOLLAR SIGN}'} are always safe
    (hint: the latter one is),
    and it's quite likely that someone uses this "feature" accidentally.
  }
  \li{
    It would make this "feature" (or lack thereof) harder to teach than it needs to be.
    The rule can be very simple: \tcode{char8_t} and some other character types
    cannot be converted to one another.
    Simple rules are easy to teach.
  }
}

\h3(id=char16_t-char32_t){What about \tcode{char16_t} and \tcode{char32_t}?}

\Bnote{
The following explanation assumes that \tcode{char16_t} and \tcode{char32_t}
are used to store a UTF-16 and UTF-32 code unit, respectively.
}

Following some negative feedback on \ref(ClangWarning),
the proposal no longer seeks to deprecate conversions between \tcode{char16_t} and \tcode{char32_t}.
While these conversions are not guaranteed to be meaningful,
there are no false positives in comparisons of UTF-16 and UTF-32 code units,
and the comparison is quite likely to be correct.

\Bnote{
There are no false positives in \tcode{char16_t} ↔ \tcode{char32_t}
because any code point in [U+0000, U+D7FF] or [U+E000, U+FFFF]
is encoded using a single code unit equivalent to the code point value,
in both UTF-16 and UTF-32.

Other code points are encoded using high surrogates ([\tt{0xD800}, \tt{0xDBFF}])
and low surrogates ([\tt{0xDC00}, \tt{0xDFFF}]).
The corresponding surrogate code points in [U+D800, U+DFFF] cannot be encoded in UTF-32.
}

It is possible to have false negatives
when searching for a UTF-32 code unit
outside the Basic Multilingual Plane (BMP) in UTF-16 text.
However, these searches are tautologically false because values
≥ \tt{0x10000} cannot (usually) be represented by \tcode{char16_t},
so compilers may catch some of them already.

It also also much less likely that \tcode{char16_t} ↔ \tcode{char32_t}
conversions actually manifest as a bug.
An application that only uses, say, Basic Latin characters and German or Norwegian
umlauts can use \tcode{char16_t} and \tcode{char32_t} interchangeably.
By contrast, mixing \tcode{char8_t} with other Unicode character types will almost
certainly blow up in the user's face if the application processes any kind of non-ASCII text.

Last but not least, UTF-8 is becoming the "default encoding", especially on the web,
while UTF-16 is increasingly becoming a "legacy encoding".
This makes it unattractive to raise warnings for \tcode{char16_t}
when the surrounding code may exist mostly for compatibility purposes,
and C++ users are not interested in sinking much time into its maintenance.
Substantially more code may be affected by a \tcode{char16_t} ↔ \tcode{char32_t}
deprecation because both types were introduced in C++11,
unlikely \tcode{char8_t}, which was added in C++20.
See also \ref(WikipediaEncodingPopularity):

\Bquote{
Recently it has become clear that the overhead of translating from/to UTF-8 on input and output,
and dealing with potential encoding errors in the input UTF-8,
overwhelms any benefits UTF-16 could offer.
So newer software systems are starting to use UTF-8.
The default string primitive used in newer programming languages,
such as Go, Julia, Rust and Swift 5, assume UTF-8 encoding.
PyPy also uses UTF-8 for its strings, and Python is looking into storing all strings in UTF-8.
Microsoft now recommends the use of UTF-8 for applications using the Windows API,
while continuing to maintain a legacy "Unicode" (meaning UTF-16) interface.
}

In summary, in \tcode{char16_t} ↔ \tcode{char32_t} comparisons,
there are no false positives,
the only false negatives are tautologically false (warnings exist),
bugs are unlikely to manifest
because code points outside the BMP are relatively uncommon,
and if deprecation warnings were raised,
that may happen in low-priority legacy code.

\Bnote{
Not one participant in SG16 voted in favor of deprecating \tcode{char16_t} ↔ \tcode{char32_t}
conversions; see \ref(#changes-since-r1).
}

\h3(id=char-and-wchar_t){What about \tcode{char} and \tcode{wchar_t}?}

As recommended by SG16,
I propose to leave \tcode{char} intact,
but deprecate conversions between \tcode{char8_t} and \tcode{wchar_t}.
Since \tcode{wchar_t} almost certainly has a different encoding than \tcode{char8_t},
this conversions is as problematic as the \tcode{char16_t} and \tcode{char32_t} conversions.

The following conversions are \u{not} deprecated:

\ul{
  \li{
    \tcode{char} ↔ \tcode{char8_t} is not deprecated because the encoding of both sides
    is likely UTF-8, in which case the conversion is obviously safe.
    Substantial amounts of code may already rely on this.
  }
  \li{
    \tcode{wchar_t} ↔ \tcode{char16_t} and \tcode{wchar_t} ↔ \tcode{char32_t}
    can also be safe, depending on the platform.
    Windows-only code can likely treat \tcode{wchar_t} and \tcode{char16_t}
    interchangeably,
    and Linux-only code may treat \tcode{wchar_t} and \tcode{char32_t} interchangeably.
  }
}

Furthermore, deprecating \em{any} conversion from \tcode{char}
to other character types is a bad idea,
and was unanimously recommended against by SG16.
In some code bases, \tcode{char} is used \em{purely} for ASCII characters and strings.
In such code bases, comparing \tcode{char} to any other character type
is always correct,
assuming that an ASCII-compatible encoding is used everywhere.

It may also be possible to deprecate conversions with \tcode{char}
depending on ordinary literal encoding,
but \tcode{char} is not necessarily using literal encoding,
and doing so would invite non-portable code that fails to compile on e.g. EBCDIC platforms,
to the great surprise of the author.

\h3(id=integer-comparisons){What about conversions with integers?}

It is quite common to compare character types to integer types.
For example, we may write \tcode{c <= 0x7f}
to check whether a character falls into the basic latin block.
There is nothing exceptionally bug-prone about comparing with say,
\tcode{0x00A0} instead of \tcode{U'\\u00A0'},
so we are not interested in deprecating character/integer conversions.

\h3(id=after-deprecation){What comes after deprecation?}

The goal is to eventually remove these conversions entirely.
Since the behavior is
easily detected (\ref(#implementation-experience)) and
easily replaced (\ref(#replacement)),
removal should be feasible within one or two revisions of the language.

Furthermore, I don't believe that having "tombstone behavior" would be necessary.
That is, allowing the conversion to happen but making the program ill-formed if it happens.
The reason is that \tcode{char8_t}, \tcode{char16_t}, and \tcode{char32_t}
rarely appear in overload sets that include types that are not characters.
\Bex{
Without "tombstone behavior",
the following code would eventually change its meaning:
\cppblock{
void f(std::any);
void f(char32_t);

int main() {
    // Currently selects f(char32_t), would select f(std::any) in the future.
    f(u8'a'); 
}
}
}

\h3(id=narrowing-conversions){Why not make these conversions narrowing?}

Another possible option (instead of deprecation or following deprecation)
is to make the affected \tcode{char8_t} conversions narrowing conversions.
This would make \tcode{char32_t{c}} for some \tcode{char8_t c} ill-formed,
but the implicit conversion from \tcode{char8_t} to \tcode{char32_t}
would remain valid.

There are multiple problems with this approach,
which is why it is not proposed:
\ul{
  \li{
    \tcode{char8_t} to \tcode{char32_t} is a widening conversion,
    making the term "narrowing conversion" comically misleading.
  }
  \li{
    A long time has passed since C++11,
    and there is a lot of code using list-initialization now.
    This means that the "blast radius" of the change may still be quite large.
    If we accept that a non-trivial amount of warnings is raised in existing code,
    this half-measure seems unattractive.
  }
  \li{
    A lot of the problematic cases are not initialization,
    but comparisons as shown in \ref(#introduction).
    Narrowing conversions play no role in equality comparison
    or in the usual arithmetic conversions.
  }
}

\h2{Impact on existing code}

It is not trivial to estimate how much code would be affected by a deprecation like this.
However, that is ultimately not what makes or breaks this proposal.
The goal is not to deprecate a rarely used feature to give it new meaning,
like \tcode{array[0,1]} prior to \ref(P1161R3).

\b{The goal is to deprecate a bug-prone and harmful feature to make the language safer.}

The longer we wait, the more mistakes will be made using \tcode{char8_t} and other types.
C++ will undoubtedly get improved support for the Unicode character types over time,
making them used more frequently,
so we better deal with this problem now than never.

\h3(id=replacement){Replacement for deprecated behavior}

If the new deprecation warnings spot a bug like in \ref(#introduction),
some work will be required to fix it,
but the deprecation will have done its job.

If the comparison is obviously safe, such as \tcode{c == U'0'} with \tcode{char8_t c},
the resolution is usually trivial, like \tcode{c == u8'0'}.
This could even be done automatically with tools like clang-tidy.


\h2{Implementation experience}

Corentin Jabot has recently implemented a \tt{-Wcharacter-conversion}
warning in Clang (\ref(ClangWarning)), which is enabled by default.
You can test this at \ref(CompilerExplorer).

However the warning is more conservative than the proposed deprecation;
it does not warn on "safe comparisons" (\ref(#safe-comparisons)).

\h2{Wording}

\style{
  ins-block .para::before {
      display: none;
  }

  .stable-ref {
      float: right;
  }
}

The following changes are relative to \ref(N5014).

\h3(show-number=false){[conv.integral]}

Change \eelis{conv.integral#1} as follows,
and split it into two paragraphs:

\Bdiff{
1 A prvalue of an integer type
can be converted to a prvalue of another integer type.
\ins{The conversion is deprecated ([depr.conv.unicode]) if
one of the types involved in the conversion is \tcode{char8_t},
and the other type is \tcode{char16_t}, \tcode{char32_t}, or \tcode{wchar_t}.}

\ins{\note{
This deprecation also applies to cv-qualified types
because prvalues of such types are adjusted to cv-unqualified types\iref{expr.type}.
}}

\ins{2} A prvalue of an unscoped enumeration type can be converted to a prvalue of an integer type.
}

\h3(show-number=false){[expr.arith.conv]}

Change \eelis{expr.arith.conv#1} as follows:

\Bdiff{
Many binary operators that expect operands of arithmetic or enumeration type
cause conversions and yield result types in a similar way.
The purpose is to yield a common type, which is also the type of the result.
This pattern is called the \i{usual arithmetic conversions}, which are defined as follows:
\ul{
  \li{
    The lvalue-to-rvalue conversion\iref{conv.lval} is applied to each operand
    and the resulting prvalues are used in place of the original operands
    for the remainder of this section.
  }
  \li{\etc}
  \li{
    Otherwise, each operand is converted to a common type \tcode{C}.
    \ins{The conversion is deprecated if one operand is \tcode{char8_t}
    and the other operand is \tcode{char16_t}, \tcode{char32_t}, or \tcode{wchar_t}.}
    The integral promotion rules\iref{conv.prom} are used
    to determine a type \tcode{T1} and type \tcode{T2} for each operand.
    Then the following rules are applied to determine C:
    \ul{
        \li{\etc}
    }
  }
}
}

\Btip{
Integral promotion converts character types to \tcode{int} or \tcode{unsigned int},
so if we didn't add this wording,
the conversion would not be deprecated.
}

\h3(show-number=false){[expr.static.cast]}

Immediately prior to \eelis{expr.static.cast#5},
insert a new paragraph:

\Bins{
An expression \math{\mi{E}} of type \i{cv} \tcode{char8_t}
can be explicitly converted to
\i{cv} \tcode{char16_t}, \i{cv} \tcode{char32_t}, or \i{cv} \tcode{wchar_t}
and vice-versa.
The effect is equivalent to
explicitly converting to \tcode{unsigned char},
then to the target type.

\note{
Integral conversions\iref{conv.integral}
between these types have the same effect and are deprecated,
unlike this explicit conversion\iref{depr.conv.unicode}.
}
}

\Btip{
The wording for \tcode{static_cast} needs to permit possibly cv-qualified types with "\i{cv}".
While cv-qualifications get dropped from expressions\iref{expr.type},
we still need to say that you can write e.g. \tcode{static_cast<const char8_t>}.
Cv-qualifications do not get dropped automatically from the \grammarterm{type-id}.
}

Do \u{not} change \eelis{expr.static.cast#5};
it is cited here for reference:

\Bquote{
Otherwise, an expression \math{\mi{E}} can be explicitly converted to a type \tcode{T}
if there is an implicit conversion sequence\iref{over.best.ics}
from \math{\mi{E}} to \tcode{T}, \etc.
\etc, the result object is direct-initialized from \math{\mi{E}}.
}

\h3(show-number=false){[depr.conv.unicode]}

Insert a new subclause in \eelis{depr} between \eelis{depr.local} and \eelis{depr.capture.this},
containing a single paragraph:

\Bins{
\h3(listed=false){Unicode character conversions \stable_ref{depr.conv.unicode}}

The following conversions are deprecated:
\ul{
  \li{
    Integral conversions\iref{conv.integral},
    where out of the types involved in the conversion,
    one is \tcode{char8_t}
    and the other is \tcode{char16_t}, \tcode{char32_t}, or \tcode{wchar_t}.
  }
  \li{
    Usual arithmetic conversions\iref{expr.arith.conv}
    where out of the operand types after lvalue-to-rvalue conversion\iref{conv.lval},
    one is \tcode{char8_t}
    and the other is \tcode{char16_t}, \tcode{char32_t}, or \tcode{wchar_t}.
  }
}
\example{
\codeblock(cpp,borders=false){
bool is_oe(char8_t c) {
    return c == U'ö';                     // \serif{deprecated}
}
void f() {
    char32_t c = u8'x';                   // \serif{deprecated}
    char32_t c = u'x';                    // \serif{OK, conversion from \tcode{char16_t} to \tcode{char32_t}}
    char8_t c = 'x';                      // \serif{OK, conversion from \tcode{char} to \tcode{char8_t}}
    is_oe(U'ö');                          // \serif{deprecated}
    is_oe(static_cast<char8_t>(U'ö'));    // \serif{OK, explicit conversion\iref{expr.static.cast}}
    is_oe((char8_t)U'ö');                 // \serif{OK, explicit conversion}
}
}
}
}

\h2{References}

\bib(
  id = N5014,
  title = Working Draft\, Programming Languages — C++,
  date = 2025-08-05,
  author = Thomas Köppe,
  link = https://wg21.link/n5014,
  long-link = https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2025/n5014.pdf,
)\
\bib(
  id = µlight,
  title = ascii_chars.hpp utilities in µlight,
  author = Jan Schultke,
  link = https://github.com/Eisenwave/ulight
)\
\bib(
  id = ClangWarning,
  title = [Clang] Add warnings when mixing different charN_t types,
  author = Corentin Jabot,
  link = https://github.com/llvm/llvm-project/pull/138708
)\
\bib(
  id = CompilerExplorer,
  title = Demonstration of -Wcharacter-conversion,
  link = https://compiler-explorer.com/z/8j9qqe8MY
)\
\bib(
  id = WikipediaEncodingPopularity,
  title = Popularity of text encodings — Popularity internally in software,
  link = https://en.wikipedia.org/wiki/Popularity_of_text_encodings#Popularity_internally_in_software,
)\
\bib(
  id = P1161R3,
  title = Deprecate uses of the comma operator in subscripting expressions,
  author = Corentin Jabot,
  link = https://wg21.link/P1161R3,
  long-link = https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1161r3.html
)\

\make_bib
